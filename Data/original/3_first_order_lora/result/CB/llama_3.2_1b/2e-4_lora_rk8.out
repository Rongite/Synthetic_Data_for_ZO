firstorder-meta-llama/Llama-3.2-1B-/home/jlong1/Downloads/Synthetic_Data_for_ZO/Data/original/CB-lora-16-2e-4-0-lora-8
STEPS: 20000
BS: 16
LR: 2e-4
EPS: 1e-3
SEED: 0
MODE: lora
LoRA RANK: 8
Extra args: --lora --lora_rank 8 
OurArguments(
C4_grad_addr=None,
C4_grad_mask=False,
GraSP_mask=False,
_n_gpu=1,
accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
batch_eval_metrics=False,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_persistent_workers=False,
dataloader_pin_memory=True,
dataloader_prefetch_factor=None,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
dispatch_batches=None,
do_eval=True,
do_predict=False,
do_train=False,
dynamic_mask=False,
dynamic_mask_step=100,
eos_token=<EOS_TOKEN>,
eval_accumulation_steps=None,
eval_delay=0,
eval_do_concat_batches=True,
eval_on_start=False,
eval_steps=500,
eval_strategy=steps,
eval_use_gather_object=False,
evaluation_strategy=steps,
fp16=True,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
grad_mask=False,
grad_save_path=None,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
gradient_checkpointing_kwargs=None,
greater_is_better=False,
group_by_length=False,
half_precision_backend=auto,
head_tuning=False,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
icl_sfc=False,
ignore_data_skip=False,
include_inputs_for_metrics=False,
include_num_input_tokens_seen=False,
include_tokens_per_second=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=0.0002,
length_column_name=length,
linear_probing=False,
load_best_model_at_end=True,
load_bfloat16=False,
load_float16=False,
load_int8=False,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=/home/jlong1/Downloads/models/synthetic_data/fo_lora/original/CB-Llama-3.2-1B-firstorder-meta-llama/Llama-3.2-1B-/home/jlong1/Downloads/Synthetic_Data_for_ZO/Data/original/CB-lora-16-2e-4-0-lora-8/runs/Apr08_15-10-31_siai-3,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=10,
logging_strategy=steps,
lora=True,
lora_alpha=16,
lora_rank=8,
lp_early_stopping=False,
lr_scheduler_kwargs={},
lr_scheduler_type=linear,
mask_path=None,
max_grad_norm=1.0,
max_length=2048,
max_new_tokens=50,
max_steps=20000,
memory_limit_scenario=False,
metric_for_best_model=loss,
model_name=meta-llama/Llama-3.2-1B,
model_weight_path=None,
mp_parameters=,
n_tokens=2,
neftune_noise_alpha=None,
no_auto_device=False,
no_cuda=False,
no_eval=False,
no_flash_attn_2=False,
no_reparam=True,
non_diff=False,
num_beams=1,
num_dev=100,
num_eval=1000,
num_prefix=5,
num_train=1000,
num_train_epochs=3.0,
num_train_sets=None,
only_train_option=True,
optim=sgd,
optim_args=None,
optim_target_modules=None,
other_task_mask=False,
outlier=False,
outlier_percentage=0.005,
output_dir=/home/jlong1/Downloads/models/synthetic_data/fo_lora/original/CB-Llama-3.2-1B-firstorder-meta-llama/Llama-3.2-1B-/home/jlong1/Downloads/Synthetic_Data_for_ZO/Data/original/CB-lora-16-2e-4-0-lora-8,
overwrite_output_dir=False,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=16,
prediction_loss_only=False,
prefix_init_by_real_act=True,
prefix_layer_id=None,
prefix_tuning=False,
prefix_tuning_one_layer=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
random_subset_weights=False,
ray_scope=last,
record_time=True,
remove_unused_columns=True,
report_to=['tensorboard', 'wandb'],
restore_callback_states_from_checkpoint=False,
result_file=None,
resume_from_checkpoint=None,
run_name=/home/jlong1/Downloads/models/synthetic_data/fo_lora/original/CB-Llama-3.2-1B-firstorder-meta-llama/Llama-3.2-1B-/home/jlong1/Downloads/Synthetic_Data_for_ZO/Data/original/CB-lora-16-2e-4-0-lora-8,
samples=1,
sampling=True,
save_grad=False,
save_model=False,
save_model_addr=None,
save_on_each_node=False,
save_on_interrupt=False,
save_only_model=False,
save_safetensors=True,
save_steps=500,
save_strategy=steps,
save_total_limit=1,
seed=42,
sfc=False,
skip_memory_metrics=True,
smaller_weight_mask=False,
split_batches=None,
squeezellm_ckpt=None,
squeezellm_wbits=4,
tag=firstorder-meta-llama/Llama-3.2-1B-/home/jlong1/Downloads/Synthetic_Data_for_ZO/Data/original/CB-lora-16-2e-4-0-lora-8,
task_name=/home/jlong1/Downloads/Synthetic_Data_for_ZO/Data/original/CB,
temperature=1.0,
tf32=None,
top_k=None,
top_p=0.95,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torch_empty_cache_steps=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
train_as_classification=True,
train_set_seed=0,
trainer=regular,
use_adam=False,
use_cpu=False,
use_full_zo_update=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_momentum=False,
use_mps_device=False,
use_sgd=False,
use_squeezellm=False,
use_squeezellm_peft=False,
verbose=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
zo_eps=0.001,
)
Detected local path: /home/jlong1/Downloads/Synthetic_Data_for_ZO/Data/original/CB
Loading CB dataset from local JSONL files: /home/jlong1/Downloads/Synthetic_Data_for_ZO/Data/original/CB
Loaded 250 samples from /home/jlong1/Downloads/Synthetic_Data_for_ZO/Data/original/CB/cb_train.jsonl
Loaded 56 samples from /home/jlong1/Downloads/Synthetic_Data_for_ZO/Data/original/CB/cb_validation.jsonl
Number of training samples loaded: 250
Number of validation samples loaded: 56
Number of training samples after label processing: 250
Number of validation samples after label processing: 56
Number of training samples after building: 250
Number of validation samples after building: 56
Training set sample count: 250
Validation set sample count: 56
The training set is completely sequential
Loading model...
Done with 1.64s
Inject lora to layer 0
Inject lora to layer 1
Inject lora to layer 2
Inject lora to layer 3
Inject lora to layer 4
Inject lora to layer 5
Inject lora to layer 6
Inject lora to layer 7
Inject lora to layer 8
Inject lora to layer 9
Inject lora to layer 10
Inject lora to layer 11
Inject lora to layer 12
Inject lora to layer 13
Inject lora to layer 14
Inject lora to layer 15
Tokenizing training samples...
Done with 0.26s
[2025-04-08 15:10:41,475] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cuda (auto detect)
SGD (
Parameter Group 0
    dampening: 0
    differentiable: False
    foreach: None
    lr: 0.0002
    maximize: False
    momentum: 0
    nesterov: False
    weight_decay: 0
)
firstorder-meta-llama/Llama-3.2-1B-/home/jlong1/Downloads/Synthetic_Data_for_ZO/Data/original/CB-lora-16-2e-4-0-lora-8
STEPS: 20000
BS: 16
LR: 2e-4
EPS: 1e-3
SEED: 0
MODE: lora
LoRA RANK: 8
Extra args: --lora --lora_rank 8 
OurArguments(
C4_grad_addr=None,
C4_grad_mask=False,
GraSP_mask=False,
_n_gpu=2,
accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
batch_eval_metrics=False,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_persistent_workers=False,
dataloader_pin_memory=True,
dataloader_prefetch_factor=None,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
dispatch_batches=None,
do_eval=True,
do_predict=False,
do_train=False,
dynamic_mask=False,
dynamic_mask_step=100,
eos_token=<EOS_TOKEN>,
eval_accumulation_steps=None,
eval_delay=0,
eval_do_concat_batches=True,
eval_on_start=False,
eval_steps=500,
eval_strategy=steps,
eval_use_gather_object=False,
evaluation_strategy=steps,
fp16=True,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
grad_mask=False,
grad_save_path=None,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
gradient_checkpointing_kwargs=None,
greater_is_better=False,
group_by_length=False,
half_precision_backend=auto,
head_tuning=False,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
icl_sfc=False,
ignore_data_skip=False,
include_inputs_for_metrics=False,
include_num_input_tokens_seen=False,
include_tokens_per_second=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=0.0002,
length_column_name=length,
linear_probing=False,
load_best_model_at_end=True,
load_bfloat16=False,
load_float16=False,
load_int8=False,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=/home/jlong1/Downloads/models/synthetic_data/fo_lora/original/CB-Llama-3.2-1B-firstorder-meta-llama/Llama-3.2-1B-/home/jlong1/Downloads/Synthetic_Data_for_ZO/Data/original/CB-lora-16-2e-4-0-lora-8/runs/Apr09_21-15-47_siai-3,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=10,
logging_strategy=steps,
lora=True,
lora_alpha=16,
lora_rank=8,
lp_early_stopping=False,
lr_scheduler_kwargs={},
lr_scheduler_type=linear,
mask_path=None,
max_grad_norm=1.0,
max_length=2048,
max_new_tokens=50,
max_steps=20000,
memory_limit_scenario=False,
metric_for_best_model=loss,
model_name=meta-llama/Llama-3.2-1B,
model_weight_path=None,
mp_parameters=,
n_tokens=2,
neftune_noise_alpha=None,
no_auto_device=False,
no_cuda=False,
no_eval=False,
no_flash_attn_2=False,
no_reparam=True,
non_diff=False,
num_beams=1,
num_dev=100,
num_eval=1000,
num_prefix=5,
num_train=1000,
num_train_epochs=3.0,
num_train_sets=None,
only_train_option=True,
optim=sgd,
optim_args=None,
optim_target_modules=None,
other_task_mask=False,
outlier=False,
outlier_percentage=0.005,
output_dir=/home/jlong1/Downloads/models/synthetic_data/fo_lora/original/CB-Llama-3.2-1B-firstorder-meta-llama/Llama-3.2-1B-/home/jlong1/Downloads/Synthetic_Data_for_ZO/Data/original/CB-lora-16-2e-4-0-lora-8,
overwrite_output_dir=False,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=16,
prediction_loss_only=False,
prefix_init_by_real_act=True,
prefix_layer_id=None,
prefix_tuning=False,
prefix_tuning_one_layer=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
random_subset_weights=False,
ray_scope=last,
record_time=True,
remove_unused_columns=True,
report_to=['tensorboard', 'wandb'],
restore_callback_states_from_checkpoint=False,
result_file=None,
resume_from_checkpoint=None,
run_name=/home/jlong1/Downloads/models/synthetic_data/fo_lora/original/CB-Llama-3.2-1B-firstorder-meta-llama/Llama-3.2-1B-/home/jlong1/Downloads/Synthetic_Data_for_ZO/Data/original/CB-lora-16-2e-4-0-lora-8,
samples=1,
sampling=True,
save_grad=False,
save_model=False,
save_model_addr=None,
save_on_each_node=False,
save_on_interrupt=False,
save_only_model=False,
save_safetensors=True,
save_steps=500,
save_strategy=steps,
save_total_limit=1,
seed=42,
sfc=False,
skip_memory_metrics=True,
smaller_weight_mask=False,
split_batches=None,
squeezellm_ckpt=None,
squeezellm_wbits=4,
tag=firstorder-meta-llama/Llama-3.2-1B-/home/jlong1/Downloads/Synthetic_Data_for_ZO/Data/original/CB-lora-16-2e-4-0-lora-8,
task_name=/home/jlong1/Downloads/Synthetic_Data_for_ZO/Data/original/CB,
temperature=1.0,
tf32=None,
top_k=None,
top_p=0.95,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torch_empty_cache_steps=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
train_as_classification=True,
train_set_seed=0,
trainer=regular,
use_adam=False,
use_cpu=False,
use_full_zo_update=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_momentum=False,
use_mps_device=False,
use_sgd=False,
use_squeezellm=False,
use_squeezellm_peft=False,
verbose=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
zo_eps=0.001,
)
Detected local path: /home/jlong1/Downloads/Synthetic_Data_for_ZO/Data/original/CB
Loading CB dataset from local JSONL files: /home/jlong1/Downloads/Synthetic_Data_for_ZO/Data/original/CB
Loaded 250 samples from /home/jlong1/Downloads/Synthetic_Data_for_ZO/Data/original/CB/cb_train.jsonl
Loaded 56 samples from /home/jlong1/Downloads/Synthetic_Data_for_ZO/Data/original/CB/cb_validation.jsonl
Number of training samples loaded: 250
Number of validation samples loaded: 56
Number of training samples after label processing: 250
Number of validation samples after label processing: 56
Number of training samples after building: 250
Number of validation samples after building: 56
Training set sample count: 250
Validation set sample count: 56
The training set is completely sequential
Loading model...
Done with 3.55s
Inject lora to layer 0
Inject lora to layer 1
Inject lora to layer 2
Inject lora to layer 3
Inject lora to layer 4
Inject lora to layer 5
Inject lora to layer 6
Inject lora to layer 7
Inject lora to layer 8
Inject lora to layer 9
Inject lora to layer 10
Inject lora to layer 11
Inject lora to layer 12
Inject lora to layer 13
Inject lora to layer 14
Inject lora to layer 15
Tokenizing training samples...
Done with 0.26s
[2025-04-09 21:15:59,455] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cuda (auto detect)
SGD (
Parameter Group 0
    dampening: 0
    differentiable: False
    foreach: None
    lr: 0.0002
    maximize: False
    momentum: 0
    nesterov: False
    weight_decay: 0
)
{'loss': 0.7465, 'learning_rate': 0.000195, 'epoch': 50.0}
{'eval_dev_loss': 0.7947973608970642, 'eval_dev_model_preparation_time': 0.0001, 'eval_dev_runtime': 2.7657, 'eval_dev_samples_per_second': 36.157, 'eval_dev_steps_per_second': 4.7, 'epoch': 50.0}
{'eval_test_loss': 0.8103947043418884, 'eval_test_model_preparation_time': 0.0001, 'eval_test_runtime': 1.5769, 'eval_test_samples_per_second': 35.512, 'eval_test_steps_per_second': 4.439, 'epoch': 50.0}
{'loss': 0.1402, 'learning_rate': 0.00019, 'epoch': 100.0}
{'eval_dev_loss': 1.5144134759902954, 'eval_dev_model_preparation_time': 0.0001, 'eval_dev_runtime': 2.7598, 'eval_dev_samples_per_second': 36.234, 'eval_dev_steps_per_second': 4.71, 'epoch': 100.0}
{'eval_test_loss': 1.7019537687301636, 'eval_test_model_preparation_time': 0.0001, 'eval_test_runtime': 1.5764, 'eval_test_samples_per_second': 35.523, 'eval_test_steps_per_second': 4.44, 'epoch': 100.0}
{'loss': 0.0017, 'learning_rate': 0.00018500000000000002, 'epoch': 150.0}
{'eval_dev_loss': 1.8151546716690063, 'eval_dev_model_preparation_time': 0.0001, 'eval_dev_runtime': 2.7617, 'eval_dev_samples_per_second': 36.209, 'eval_dev_steps_per_second': 4.707, 'epoch': 150.0}
{'eval_test_loss': 2.0478107929229736, 'eval_test_model_preparation_time': 0.0001, 'eval_test_runtime': 1.5762, 'eval_test_samples_per_second': 35.529, 'eval_test_steps_per_second': 4.441, 'epoch': 150.0}
{'loss': 0.0006, 'learning_rate': 0.00018, 'epoch': 200.0}
{'eval_dev_loss': 1.9686784744262695, 'eval_dev_model_preparation_time': 0.0001, 'eval_dev_runtime': 2.7643, 'eval_dev_samples_per_second': 36.175, 'eval_dev_steps_per_second': 4.703, 'epoch': 200.0}
{'eval_test_loss': 2.200467586517334, 'eval_test_model_preparation_time': 0.0001, 'eval_test_runtime': 1.5751, 'eval_test_samples_per_second': 35.552, 'eval_test_steps_per_second': 4.444, 'epoch': 200.0}
{'loss': 0.0004, 'learning_rate': 0.000175, 'epoch': 250.0}
{'eval_dev_loss': 2.068302869796753, 'eval_dev_model_preparation_time': 0.0001, 'eval_dev_runtime': 2.7727, 'eval_dev_samples_per_second': 36.066, 'eval_dev_steps_per_second': 4.689, 'epoch': 250.0}
{'eval_test_loss': 2.3084347248077393, 'eval_test_model_preparation_time': 0.0001, 'eval_test_runtime': 1.5771, 'eval_test_samples_per_second': 35.508, 'eval_test_steps_per_second': 4.439, 'epoch': 250.0}
{'loss': 0.0002, 'learning_rate': 0.00017, 'epoch': 300.0}
{'eval_dev_loss': 2.1395576000213623, 'eval_dev_model_preparation_time': 0.0001, 'eval_dev_runtime': 2.7632, 'eval_dev_samples_per_second': 36.189, 'eval_dev_steps_per_second': 4.705, 'epoch': 300.0}
{'eval_test_loss': 2.3914778232574463, 'eval_test_model_preparation_time': 0.0001, 'eval_test_runtime': 1.5773, 'eval_test_samples_per_second': 35.504, 'eval_test_steps_per_second': 4.438, 'epoch': 300.0}
{'loss': 0.0002, 'learning_rate': 0.000165, 'epoch': 350.0}
{'eval_dev_loss': 2.1961934566497803, 'eval_dev_model_preparation_time': 0.0001, 'eval_dev_runtime': 2.7659, 'eval_dev_samples_per_second': 36.154, 'eval_dev_steps_per_second': 4.7, 'epoch': 350.0}
{'eval_test_loss': 2.4542076587677, 'eval_test_model_preparation_time': 0.0001, 'eval_test_runtime': 1.5756, 'eval_test_samples_per_second': 35.542, 'eval_test_steps_per_second': 4.443, 'epoch': 350.0}
{'loss': 0.0002, 'learning_rate': 0.00016, 'epoch': 400.0}
{'eval_dev_loss': 2.2369205951690674, 'eval_dev_model_preparation_time': 0.0001, 'eval_dev_runtime': 2.7623, 'eval_dev_samples_per_second': 36.202, 'eval_dev_steps_per_second': 4.706, 'epoch': 400.0}
{'eval_test_loss': 2.5057027339935303, 'eval_test_model_preparation_time': 0.0001, 'eval_test_runtime': 1.5777, 'eval_test_samples_per_second': 35.495, 'eval_test_steps_per_second': 4.437, 'epoch': 400.0}
{'loss': 0.0001, 'learning_rate': 0.000155, 'epoch': 450.0}
{'eval_dev_loss': 2.2752163410186768, 'eval_dev_model_preparation_time': 0.0001, 'eval_dev_runtime': 2.7722, 'eval_dev_samples_per_second': 36.073, 'eval_dev_steps_per_second': 4.689, 'epoch': 450.0}
{'eval_test_loss': 2.5477232933044434, 'eval_test_model_preparation_time': 0.0001, 'eval_test_runtime': 1.5786, 'eval_test_samples_per_second': 35.474, 'eval_test_steps_per_second': 4.434, 'epoch': 450.0}
{'loss': 0.0001, 'learning_rate': 0.00015000000000000001, 'epoch': 500.0}
{'eval_dev_loss': 2.311448812484741, 'eval_dev_model_preparation_time': 0.0001, 'eval_dev_runtime': 2.7705, 'eval_dev_samples_per_second': 36.094, 'eval_dev_steps_per_second': 4.692, 'epoch': 500.0}
{'eval_test_loss': 2.5954506397247314, 'eval_test_model_preparation_time': 0.0001, 'eval_test_runtime': 1.5734, 'eval_test_samples_per_second': 35.591, 'eval_test_steps_per_second': 4.449, 'epoch': 500.0}
{'loss': 0.0001, 'learning_rate': 0.000145, 'epoch': 550.0}
{'eval_dev_loss': 2.3310539722442627, 'eval_dev_model_preparation_time': 0.0001, 'eval_dev_runtime': 2.7631, 'eval_dev_samples_per_second': 36.191, 'eval_dev_steps_per_second': 4.705, 'epoch': 550.0}
{'eval_test_loss': 2.6214606761932373, 'eval_test_model_preparation_time': 0.0001, 'eval_test_runtime': 1.5775, 'eval_test_samples_per_second': 35.498, 'eval_test_steps_per_second': 4.437, 'epoch': 550.0}
{'loss': 0.0001, 'learning_rate': 0.00014, 'epoch': 600.0}
{'eval_dev_loss': 2.357093334197998, 'eval_dev_model_preparation_time': 0.0001, 'eval_dev_runtime': 2.7658, 'eval_dev_samples_per_second': 36.156, 'eval_dev_steps_per_second': 4.7, 'epoch': 600.0}
{'eval_test_loss': 2.645576000213623, 'eval_test_model_preparation_time': 0.0001, 'eval_test_runtime': 1.5752, 'eval_test_samples_per_second': 35.551, 'eval_test_steps_per_second': 4.444, 'epoch': 600.0}
{'loss': 0.0001, 'learning_rate': 0.00013500000000000003, 'epoch': 650.0}
{'eval_dev_loss': 2.3860559463500977, 'eval_dev_model_preparation_time': 0.0001, 'eval_dev_runtime': 2.7713, 'eval_dev_samples_per_second': 36.084, 'eval_dev_steps_per_second': 4.691, 'epoch': 650.0}
{'eval_test_loss': 2.6684908866882324, 'eval_test_model_preparation_time': 0.0001, 'eval_test_runtime': 1.5756, 'eval_test_samples_per_second': 35.541, 'eval_test_steps_per_second': 4.443, 'epoch': 650.0}
{'loss': 0.0001, 'learning_rate': 0.00013000000000000002, 'epoch': 700.0}
{'eval_dev_loss': 2.400555372238159, 'eval_dev_model_preparation_time': 0.0001, 'eval_dev_runtime': 2.7688, 'eval_dev_samples_per_second': 36.117, 'eval_dev_steps_per_second': 4.695, 'epoch': 700.0}
{'eval_test_loss': 2.6923813819885254, 'eval_test_model_preparation_time': 0.0001, 'eval_test_runtime': 1.5769, 'eval_test_samples_per_second': 35.513, 'eval_test_steps_per_second': 4.439, 'epoch': 700.0}
{'loss': 0.0001, 'learning_rate': 0.000125, 'epoch': 750.0}
{'eval_dev_loss': 2.42374324798584, 'eval_dev_model_preparation_time': 0.0001, 'eval_dev_runtime': 2.7657, 'eval_dev_samples_per_second': 36.157, 'eval_dev_steps_per_second': 4.7, 'epoch': 750.0}
{'eval_test_loss': 2.718902349472046, 'eval_test_model_preparation_time': 0.0001, 'eval_test_runtime': 1.5763, 'eval_test_samples_per_second': 35.526, 'eval_test_steps_per_second': 4.441, 'epoch': 750.0}
{'loss': 0.0001, 'learning_rate': 0.00012, 'epoch': 800.0}
{'eval_dev_loss': 2.4358162879943848, 'eval_dev_model_preparation_time': 0.0001, 'eval_dev_runtime': 2.7623, 'eval_dev_samples_per_second': 36.202, 'eval_dev_steps_per_second': 4.706, 'epoch': 800.0}
{'eval_test_loss': 2.7396883964538574, 'eval_test_model_preparation_time': 0.0001, 'eval_test_runtime': 1.5776, 'eval_test_samples_per_second': 35.496, 'eval_test_steps_per_second': 4.437, 'epoch': 800.0}
{'loss': 0.0001, 'learning_rate': 0.00011499999999999999, 'epoch': 850.0}
{'eval_dev_loss': 2.4511520862579346, 'eval_dev_model_preparation_time': 0.0001, 'eval_dev_runtime': 2.7577, 'eval_dev_samples_per_second': 36.263, 'eval_dev_steps_per_second': 4.714, 'epoch': 850.0}
{'eval_test_loss': 2.757335901260376, 'eval_test_model_preparation_time': 0.0001, 'eval_test_runtime': 1.5772, 'eval_test_samples_per_second': 35.505, 'eval_test_steps_per_second': 4.438, 'epoch': 850.0}
{'loss': 0.0, 'learning_rate': 0.00011000000000000002, 'epoch': 900.0}
{'eval_dev_loss': 2.463783025741577, 'eval_dev_model_preparation_time': 0.0001, 'eval_dev_runtime': 2.7745, 'eval_dev_samples_per_second': 36.043, 'eval_dev_steps_per_second': 4.686, 'epoch': 900.0}
{'eval_test_loss': 2.7728123664855957, 'eval_test_model_preparation_time': 0.0001, 'eval_test_runtime': 1.5779, 'eval_test_samples_per_second': 35.49, 'eval_test_steps_per_second': 4.436, 'epoch': 900.0}
{'loss': 0.0, 'learning_rate': 0.000105, 'epoch': 950.0}
{'eval_dev_loss': 2.480417251586914, 'eval_dev_model_preparation_time': 0.0001, 'eval_dev_runtime': 2.7607, 'eval_dev_samples_per_second': 36.222, 'eval_dev_steps_per_second': 4.709, 'epoch': 950.0}
{'eval_test_loss': 2.791205883026123, 'eval_test_model_preparation_time': 0.0001, 'eval_test_runtime': 1.5773, 'eval_test_samples_per_second': 35.504, 'eval_test_steps_per_second': 4.438, 'epoch': 950.0}
{'loss': 0.0, 'learning_rate': 0.0001, 'epoch': 1000.0}
{'eval_dev_loss': 2.4910459518432617, 'eval_dev_model_preparation_time': 0.0001, 'eval_dev_runtime': 2.7677, 'eval_dev_samples_per_second': 36.131, 'eval_dev_steps_per_second': 4.697, 'epoch': 1000.0}
