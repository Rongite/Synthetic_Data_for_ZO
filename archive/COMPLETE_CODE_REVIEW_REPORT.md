# Complete Code Review Report - Pipeline Implementation Issues

**Review Date**: 2026-01-01
**Review Scope**: In-depth code implementation review based on all workflows in `COMPLETE_PIPELINE_SIMULATION.md`
**Reviewer**: Claude Code Agent
**Project**: Synthetic_Data_for_ZO

---

## ğŸ“Š Executive Summary

| Severity Level | Count | Impact |
|---------|------|------|
| ğŸ”´ P0 Critical | 5 | Completely blocks pipeline execution |
| ğŸŸ  P1 High | 4 | Significantly impacts user experience and data quality |
| ğŸŸ¡ P2 Medium | 3 | Affects code quality and maintainability |
| ğŸŸ¢ P3 Low | 2 | Minor issues |
| **Total** | **14** | - |

**Key Finding**: Current code contains 5 P0 critical issues that prevent the entire two-stage pipeline from running properly.

---

## ğŸ”´ P0 Critical Issues (Must Fix)

### Issue 1: Incorrect data file path in annotate_samples.py âš ï¸ CRITICAL

**File**: `automation/stage1_generation/tools/annotate_samples.py:259`
**Related SIMULATION**: Scenario 1 Steps 6-7 (lines 295-406)

**Issue Description**:
```python
# âŒ Wrong: Reading directly from parent directory
train_file = current_dir.parent / f"{dataset_name}_train.jsonl"
```

**Root Cause**:
Data files are actually stored in the **dataset subdirectory** (generated by generator.py:252):
```python
# generator.py actual path
dataset_dir = os.path.join("{output_dir}", "{dataset_cfg.get('dataset_name', ...)}")
output_file = os.path.join(dataset_dir, "{dataset_cfg['task_name']}_train.jsonl")
# Actual location: Data_v2/synthetic/_shared/Copa/temp09_topp10_gpt4o/Copa/copa_train.jsonl
```

**Impact**:
- âŒ Checkpoint 2A (samples 21-40 annotation) completely fails
- âŒ Checkpoint 2B (samples 41-80 annotation) completely fails
- âŒ Blocks the entire second half of the two-stage workflow
- âŒ User receives `FileNotFoundError`

**Fix**:
```python
# âœ… Correct: Read from dataset subdirectory
dataset_task_name = dataset_cfg.get('task_name', 'copa')
dataset_display_name = dataset_cfg.get('dataset_name', dataset_task_name.capitalize())
train_file = current_dir.parent / dataset_display_name / f"{dataset_task_name}_train.jsonl"
```

**Test Validation**:
```bash
# Test after fix
cd Data_v2/synthetic/_shared/Copa/temp09_topp10_gpt4o/scripts/
python ../../../../../../automation/stage1_generation/tools/annotate_samples.py --range 21-40
# Should find: ../Copa/copa_train.jsonl
```

---

### Issue 2: validate.py depends on unmerged training data âš ï¸ CRITICAL

**File**: `automation/stage1_generation/generator.py:399`
**Related SIMULATION**: Scenario 1 Step 9 (lines 464-519)

**Issue Description**:
```python
# validate.py generated by generator.py
synthetic_file = os.path.join(dataset_dir, "{dataset_cfg['task_name']}_train.jsonl")
with open(synthetic_file, 'r', encoding='utf-8') as f:
    for line in f:
        synthetic_data.append(json.loads(line.strip()))
```

**Root Cause**:
In two-stage mode, training data is split into:
- `copa_train_top20.jsonl` (generated by rephrase_top20.py)
- `copa_train_rest.jsonl` (generated by rephrase_rest.py)
- `copa_train.jsonl` **requires manual merge**

However, validate.py expects `copa_train.jsonl` to exist. SIMULATION step 5 (lines 279-289) requires user to manually execute:
```bash
$ cat ../Copa/copa_train_top20.jsonl ../Copa/copa_train_rest.jsonl > ../Copa/copa_train.jsonl
```

**Impact**:
- âŒ If user forgets to merge, validate.py fails with file not found error
- âŒ SIMULATION step 9 (validate.py) completely fails
- âŒ Increases user operation complexity and error probability

**Fix Option 1 (Recommended)**: Auto-merge in rephrase_rest.py
```python
# Add after generator.py:296 (when generating rephrase_rest.py)
merge_code = '''
# Auto-merge top20 and rest data
print("\\nMerging top20 and rest data...")
top20_file = os.path.join(dataset_dir, "{dataset_cfg['task_name']}_train_top20.jsonl")
rest_file = os.path.join(dataset_dir, "{dataset_cfg['task_name']}_train_rest.jsonl")
merged_file = os.path.join(dataset_dir, "{dataset_cfg['task_name']}_train.jsonl")

if os.path.exists(top20_file) and os.path.exists(rest_file):
    with open(merged_file, 'w', encoding='utf-8') as out_f:
        # Copy top20
        with open(top20_file, 'r', encoding='utf-8') as in_f:
            out_f.write(in_f.read())
        # Append rest
        with open(rest_file, 'r', encoding='utf-8') as in_f:
            out_f.write(in_f.read())
    print(f"âœ“ Auto-merged: {{merged_file}}")
    print(f"  - top20: {{top20_file}}")
    print(f"  - rest: {{rest_file}}")
else:
    print(f"âš ï¸  Top20 or rest files not found, skipping merge")
'''
```

**Fix Option 2**: Auto-detect and merge in validate.py
```python
# In validate.py data loading section
if not os.path.exists(synthetic_file):
    # Try to merge top20 and rest
    top20_file = os.path.join(dataset_dir, "{dataset_cfg['task_name']}_train_top20.jsonl")
    rest_file = os.path.join(dataset_dir, "{dataset_cfg['task_name']}_train_rest.jsonl")

    if os.path.exists(top20_file) and os.path.exists(rest_file):
        print("âš ï¸  Training file not found, auto-merging top20 and rest...")
        # Execute merge logic
    else:
        raise FileNotFoundError(f"Training file not found: {synthetic_file}")
```

---

### Issue 3: Missing top_p parameter in rephrase scripts âš ï¸ CRITICAL

**File**: `automation/stage1_generation/generator.py:271-277`
**Related SIMULATION**: Data generation steps in all scenarios

**Issue Description**:
```python
# âŒ Generated script missing top_p parameter
response = client.chat.completions.create(
    model="{gen_cfg['model']}",
    messages=[
        {{"role": "user", "content": prompt}}
    ],
    temperature={gen_cfg['temperature']}  # âŒ No top_p
)
```

However, the config file explicitly specifies top_p parameter (see Batch solution parameter fingerprint calculation):
```yaml
# stage1_full_example_copa.yaml
generation:
  model: "gpt-4o"
  temperature: 0.9
  top_p: 1.0  # âŒ Being ignored
```

**Root Cause**:
- `experiment_manager_batch.py:32` includes top_p in fingerprint calculation
- `generator.py:276` doesn't pass top_p to API call
- Results in **experiments with same fingerprint potentially generating different data** (due to inconsistent actual API parameters)

**Impact**:
- âŒ Batch deduplication mechanism fails (same fingerprint but different top_p generates different data)
- âŒ Cannot accurately reproduce experiment results
- âŒ Parameter study experiments (like SIMULATION scenario 7) cannot proceed correctly

**Fix**:
```python
# âœ… Add top_p and other sampling parameters
response = client.chat.completions.create(
    model="{gen_cfg['model']}",
    messages=[
        {{"role": "user", "content": prompt}}
    ],
    temperature={gen_cfg['temperature']},
    top_p={gen_cfg.get('top_p', 1.0)},
    max_tokens={gen_cfg.get('max_tokens', 256)},
    frequency_penalty={gen_cfg.get('frequency_penalty', 0.0)},
    presence_penalty={gen_cfg.get('presence_penalty', 0.0)}
)
```

**Related Impact**:
Need to synchronously fix fingerprint calculation in `experiment_manager_batch.py:29-36` to ensure included parameters match API calls.

---

### é—®é¢˜4: validate.pyç»Ÿè®¡é€»è¾‘é”™è¯¯ âš ï¸ CRITICAL

**æ–‡ä»¶**: `automation/stage1_generation/generator.py:422-430, 473-475`
**å¯¹åº”SIMULATION**: åœºæ™¯1 æ­¥éª¤9ï¼ˆ464-519è¡Œï¼‰

**é—®é¢˜æè¿°**:
```python
# éªŒè¯å¾ªç¯
for i in tqdm(range(min(len(original_data), len(synthetic_data)))):
    original = original_data[i]
    synthetic = synthetic_data[i]

    # æ’é™¤æ ·æœ¬21-40ï¼ˆç´¢å¼•20-39ï¼‰
    if 20 <= i < 40:
        # ç›´æ¥ä½¿ç”¨åˆæˆæ•°æ®ï¼Œä¸ç»è¿‡judgeréªŒè¯
        out_file.write(json.dumps(synthetic, ensure_ascii=False) + "\\n")
        correct_count += 1  # âŒ è®¡å…¥é€šè¿‡æ•°
        total_count += 1    # âŒ è®¡å…¥æ€»æ•°
        continue

    # ... éªŒè¯é€»è¾‘ ...
    total_count += 1

# æœ€ç»ˆç»Ÿè®¡
accuracy = correct_count / total_count  # âŒ åŒ…å«äº†æœªéªŒè¯çš„æ ·æœ¬
print(f"é€šè¿‡ç‡: {{correct_count}}/{{total_count}} = {{accuracy:.2%}}")
```

**æ ¹æœ¬åŸå› **:
æ ·æœ¬21-40è¢«è·³è¿‡éªŒè¯ï¼ˆé¿å…æ•°æ®æ³„éœ²ï¼Œè¿™æ˜¯æ­£ç¡®çš„ï¼‰ï¼Œä½†å®ƒä»¬ï¼š
1. è¢«è®¡å…¥`total_count`ï¼ˆé”™è¯¯ï¼‰
2. è¢«è®¡å…¥`correct_count`ï¼ˆé”™è¯¯ï¼‰
3. å¯¼è‡´å‡†ç¡®ç‡ç»Ÿè®¡ä¸å‡†ç¡®

**å½±å“**:
- âŒ å‡†ç¡®ç‡ç»Ÿè®¡è™šé«˜ï¼ˆ81-400æ ·æœ¬ä¸­ï¼Œ20ä¸ªæ ·æœ¬æ— æ¡ä»¶æ ‡è®°ä¸º"é€šè¿‡"ï¼‰
- âŒ ç”¨æˆ·æ— æ³•å‡†ç¡®è¯„ä¼°validation promptè´¨é‡
- âŒ SIMULATIONæ­¥éª¤9çš„è¾“å‡ºä¸æ–‡æ¡£ä¸ç¬¦

**SIMULATIONæœŸæœ›è¾“å‡º**ï¼ˆæ­¥éª¤9, 490-495è¡Œï¼‰:
```
æ€»éªŒè¯æ ·æœ¬: 320 (æ ·æœ¬81-400)  # âœ… åº”è¯¥æ’é™¤1-80
åˆ¤æ–­ä¸º same: 307 (95.9%)
åˆ¤æ–­ä¸º not the same: 13 (4.1%)
```

**å®é™…è¾“å‡º**ï¼ˆå½“å‰ä»£ç ï¼‰:
```
æ€»éªŒè¯æ ·æœ¬: 400 (æ ·æœ¬1-400)   # âŒ é”™è¯¯åœ°åŒ…å«äº†21-40
åˆ¤æ–­ä¸º same: 327 (81.8%)       # âŒ è™šé«˜ï¼ˆ327=20+307ï¼‰
```

**ä¿®å¤æ–¹æ¡ˆ**:
```python
# âœ… æ–¹æ¡ˆ1: åœ¨å¾ªç¯å¤–å•ç‹¬ç»Ÿè®¡
samples_21_40_count = 0

for i in tqdm(range(min(len(original_data), len(synthetic_data)))):
    original = original_data[i]
    synthetic = synthetic_data[i]

    if 20 <= i < 40:
        # ç›´æ¥ä½¿ç”¨åˆæˆæ•°æ®ï¼Œä¸ç»è¿‡judgeréªŒè¯
        out_file.write(json.dumps(synthetic, ensure_ascii=False) + "\\n")
        samples_21_40_count += 1  # âœ… å•ç‹¬ç»Ÿè®¡
        continue

    # ... éªŒè¯é€»è¾‘ï¼ˆä¸å˜ï¼‰...
    total_count += 1

# æœ€ç»ˆç»Ÿè®¡
accuracy = correct_count / total_count if total_count > 0 else 0
print(f"\\néªŒè¯å®Œæˆ!")
print(f"éªŒè¯æ ·æœ¬: {{total_count}} (æ’é™¤äº†1-20å’Œ21-40)")
print(f"æ ·æœ¬21-40: {{samples_21_40_count}} (è·³è¿‡éªŒè¯ï¼Œç›´æ¥ä½¿ç”¨)")
print(f"é€šè¿‡ç‡: {{correct_count}}/{{total_count}} = {{accuracy:.2%}}")
```

**æµ‹è¯•éªŒè¯**:
ä½¿ç”¨400æ¡æ•°æ®è¿è¡Œvalidate.pyï¼ŒéªŒè¯ç»Ÿè®¡è¾“å‡ºæ˜¯å¦ä¸ºï¼š
- éªŒè¯æ ·æœ¬: 320ï¼ˆç´¢å¼•41-400ï¼‰
- æ ·æœ¬21-40: 20ï¼ˆè·³è¿‡éªŒè¯ï¼‰

---

### é—®é¢˜5: review_top20.pyç”Ÿæˆçš„validatedæ–‡ä»¶æœªè¢«ä½¿ç”¨ âš ï¸ DESIGN FLAW

**æ–‡ä»¶**: `automation/stage1_generation/tools/review_top20.py:284-288`
**å¯¹åº”SIMULATION**: åœºæ™¯1 æ­¥éª¤3ï¼ˆ183-261è¡Œï¼‰

**é—®é¢˜æè¿°**:
```python
# review_top20.pyä¿å­˜rejection samplingåçš„æ•°æ®
dataset_output_dir = current_dir.parent / dataset_display_name
output_file = dataset_output_dir / f"{dataset_name}_train_top20_validated.jsonl"
save_jsonl(final_data, str(output_file))
print(f"âœ“ Rejection samplingå®Œæˆ: {output_file}")
```

ä½†åç»­æµç¨‹ä½¿ç”¨çš„æ˜¯ï¼š
- `rephrase_rest.py` è¯»å– `copa_train_top20.jsonl`ï¼ˆæœªç»rejection samplingï¼‰
- æœ€ç»ˆåˆå¹¶æ—¶ä¹Ÿä½¿ç”¨ `copa_train_top20.jsonl`ï¼ˆæœªç»rejection samplingï¼‰

**æ•°æ®æµé”™è¯¯**:
```
rephrase_top20.py â†’ copa_train_top20.jsonl (åŸå§‹æ”¹å†™)
                     â†“
review_top20.py   â†’ copa_train_top20_validated.jsonl (rejection samplingå)
                     â†“
                     âŒ è¢«å¿½ç•¥ï¼

åˆå¹¶æ­¥éª¤ä½¿ç”¨     â†’ copa_train_top20.jsonl (åŸå§‹æ”¹å†™ï¼Œæœªç»rejection sampling)
```

**å½±å“**:
- âŒ æ–­ç‚¹1çš„rejection samplingå®Œå…¨å¤±æ•ˆ
- âŒ ä¸åˆæ ¼æ ·æœ¬æ²¡æœ‰è¢«æ›¿æ¢ä¸ºåŸå§‹æ•°æ®
- âŒ æœ€ç»ˆè®­ç»ƒæ•°æ®åŒ…å«ä¸åˆæ ¼çš„æ”¹å†™æ ·æœ¬
- âŒ SIMULATIONæ­¥éª¤3ï¼ˆ237-246è¡Œï¼‰çš„rejection samplingåŠŸèƒ½æœªå®ç°

**ä¿®å¤æ–¹æ¡ˆ1ï¼ˆæ¨èï¼‰**: ç›´æ¥è¦†ç›–åŸæ–‡ä»¶
```python
# review_top20.pyä¿®æ”¹
output_file = dataset_output_dir / f"{dataset_name}_train_top20.jsonl"  # âœ… ç›´æ¥è¦†ç›–
save_jsonl(final_data, str(output_file))
print(f"âœ“ Rejection samplingå®Œæˆï¼ˆå·²è¦†ç›–åŸæ–‡ä»¶ï¼‰: {output_file}")
```

**ä¿®å¤æ–¹æ¡ˆ2**: ä¿®æ”¹åˆå¹¶é€»è¾‘ä½¿ç”¨validatedæ–‡ä»¶
```python
# åœ¨åˆå¹¶è„šæœ¬ä¸­
top20_file = f"{dataset_name}_train_top20_validated.jsonl"  # âœ… ä½¿ç”¨validatedç‰ˆæœ¬
if not os.path.exists(top20_file):
    top20_file = f"{dataset_name}_train_top20.jsonl"  # å›é€€åˆ°åŸå§‹æ–‡ä»¶
```

---

## ğŸŸ  P1 é«˜ä¼˜å…ˆçº§é—®é¢˜

### é—®é¢˜6: few-shotæ³¨å…¥ä½ç½®ä¸å¤Ÿç²¾ç¡®

**æ–‡ä»¶**: `automation/stage1_generation/tools/review_top20.py:177-196`
**å¯¹åº”SIMULATION**: åœºæ™¯1 æ­¥éª¤3ï¼ˆ183-261è¡Œï¼‰

**é—®é¢˜æè¿°**:
```python
# æŸ¥æ‰¾æœ€åä¸€ä¸ªimportè¯­å¥
insert_line = 0
for i, line in enumerate(lines):
    if line.startswith('import ') or line.startswith('from '):
        insert_line = i + 1

# æ’å…¥few-shot
lines.insert(insert_line + 1, '\n' + fewshot_text)
```

**æ½œåœ¨é—®é¢˜**:
1. å¦‚æœimportä¹‹åç«‹å³æ˜¯APIé…ç½®ä»£ç ï¼Œfew-shotä¼šè¢«æ’å…¥åˆ°ä¸­é—´
2. å¤šè¡Œimportæˆ–å¸¦æ‹¬å·çš„importä¼šå¯¼è‡´ä½ç½®é”™è¯¯
3. å¦‚æœæ–‡ä»¶æœ‰`# Import section`æ³¨é‡Šï¼Œå¯èƒ½æ’å…¥åˆ°æ³¨é‡Šå‰

**å®é™…æ¡ˆä¾‹**:
```python
import json
from openai import OpenAI

# âŒ Few-shotè¢«æ³¨å…¥åˆ°è¿™é‡Œ
# APIé…ç½®ï¼ˆä»é…ç½®æ–‡ä»¶è¯»å–ï¼‰
API_KEY = "..."
client = OpenAI(...)

# âœ… åº”è¯¥æ³¨å…¥åˆ°è¿™é‡Œ
def generate_prompt(...):
```

**å½±å“**:
- ğŸŸ  Few-shotå¯èƒ½è¢«æ’å…¥åˆ°é”™è¯¯ä½ç½®
- ğŸŸ  å¯¼è‡´ç”Ÿæˆçš„rephrase_rest.pyè¯­æ³•é”™è¯¯æˆ–æ— æ³•ä½¿ç”¨few-shot
- ğŸŸ  éœ€è¦ç”¨æˆ·æ‰‹åŠ¨ä¿®æ­£è„šæœ¬

**ä¿®å¤æ–¹æ¡ˆ**:
```python
# âœ… æ›´ç²¾ç¡®çš„æ³¨å…¥ä½ç½®ï¼šåœ¨APIå®¢æˆ·ç«¯åˆå§‹åŒ–ä¹‹å
insert_line = 0
client_init_found = False

for i, line in enumerate(lines):
    if 'client = OpenAI' in line:
        # æ‰¾åˆ°clientåˆå§‹åŒ–è¯­å¥ï¼Œç»§ç»­æŸ¥æ‰¾é—­åˆæ‹¬å·
        for j in range(i+1, len(lines)):
            if ')' in lines[j] and 'client' not in lines[j]:
                insert_line = j + 1
                client_init_found = True
                break
        break

if not client_init_found:
    # å¤‡ç”¨ï¼šåœ¨æ‰€æœ‰importä¹‹åæ’å…¥
    for i, line in enumerate(lines):
        if line.strip() and not line.startswith('import') and not line.startswith('from') and not line.startswith('#'):
            insert_line = i
            break

# æ’å…¥few-shotï¼ˆå¸¦åˆ†éš”æ³¨é‡Šï¼‰
separator = "\n# " + "="*70 + "\n# Few-shot Examples (Injected by review_top20.py)\n# " + "="*70 + "\n"
lines.insert(insert_line, separator + fewshot_text)
```

---

### é—®é¢˜7: æ•°æ®é›†ç›®å½•å‘½åé€»è¾‘ä¸ä¸€è‡´

**æ–‡ä»¶**: å¤šä¸ªæ–‡ä»¶
**å¯¹åº”SIMULATION**: æ‰€æœ‰åœºæ™¯

**é—®é¢˜åˆ†æ**:

| æ–‡ä»¶ | è·å–dataset_nameçš„æ–¹å¼ | è·å–dataset_display_nameçš„æ–¹å¼ |
|------|----------------------|----------------------------|
| generator.py:252 | cfg.get('task_name') | dataset_cfg.get('dataset_name', cfg.get('task_name', 'Dataset')) |
| review_top20.py:219-220 | dataset_cfg.get('task_name', 'dataset') | dataset_cfg.get('dataset_name', dataset_name.capitalize()) |
| annotate_samples.py:252 | dataset_cfg.get('task_name', 'copa') | âŒ **ç¼ºå¤±** |

**å½±å“**:
- ğŸŸ  annotate_samples.pyæ— æ³•æ‰¾åˆ°æ•°æ®é›†å­ç›®å½•
- ğŸŸ  ä¸åŒå·¥å…·ä¹‹é—´çš„ç›®å½•åå¯èƒ½ä¸åŒ¹é…
- ğŸŸ  é…ç½®æ–‡ä»¶ä¸­dataset_nameå’Œtask_nameä¸ä¸€è‡´æ—¶ä¼šå‡ºé”™

**ä¿®å¤æ–¹æ¡ˆ**: ç»Ÿä¸€æ‰€æœ‰å·¥å…·çš„å‘½åé€»è¾‘
```python
# âœ… åœ¨æ‰€æœ‰å·¥å…·è„šæœ¬ä¸­ä½¿ç”¨ç»Ÿä¸€é€»è¾‘
def get_dataset_names(dataset_cfg):
    """ç»Ÿä¸€è·å–æ•°æ®é›†åç§°çš„å‡½æ•°"""
    task_name = dataset_cfg.get('task_name', 'dataset')  # å°å†™ï¼Œç”¨äºæ–‡ä»¶å
    display_name = dataset_cfg.get('dataset_name', task_name.capitalize())  # å¤§å†™ï¼Œç”¨äºç›®å½•å
    return task_name, display_name

# ä½¿ç”¨æ–¹å¼
dataset_task_name, dataset_display_name = get_dataset_names(dataset_cfg)
train_file = current_dir.parent / dataset_display_name / f"{dataset_task_name}_train.jsonl"
```

æˆ–è€…åˆ›å»ºä¸€ä¸ªå…±äº«çš„`utils.py`:
```python
# automation/stage1_generation/utils.py
def get_dataset_paths(config, current_dir):
    """ç»Ÿä¸€è·å–æ•°æ®é›†è·¯å¾„çš„å·¥å…·å‡½æ•°"""
    dataset_cfg = config.get('dataset', {})
    task_name = dataset_cfg.get('task_name', 'dataset')
    display_name = dataset_cfg.get('dataset_name', task_name.capitalize())

    dataset_dir = current_dir.parent / display_name
    return {
        'task_name': task_name,
        'display_name': display_name,
        'dataset_dir': dataset_dir,
        'train_file': dataset_dir / f"{task_name}_train.jsonl",
        'validation_file': dataset_dir / f"{task_name}_validation.jsonl",
        'test_file': dataset_dir / f"{task_name}_test.jsonl"
    }
```

---

### é—®é¢˜8: validation.pyçš„few-shotåŠ è½½é€»è¾‘å¯èƒ½å¤±è´¥

**æ–‡ä»¶**: `automation/stage1_generation/generator.py:329-342`
**å¯¹åº”SIMULATION**: åœºæ™¯1 æ­¥éª¤9ï¼ˆ464-519è¡Œï¼‰

**é—®é¢˜æè¿°**:
```python
# ç”Ÿæˆçš„validate.pyå°è¯•åŠ è½½few-shot
VALIDATION_FEWSHOT_EXAMPLES = []
try:
    checkpoint_file = Path(__file__).parent.parent / "validation_checkpoints" / "validation_fewshot.json"
    if checkpoint_file.exists():
        with open(checkpoint_file, 'r', encoding='utf-8') as f:
            fewshot_data = json.load(f)
            VALIDATION_FEWSHOT_EXAMPLES = fewshot_data.get('examples', [])
        print(f"âœ“ åŠ è½½äº† {{len(VALIDATION_FEWSHOT_EXAMPLES)}} ä¸ªè‡ªåŠ¨ç”Ÿæˆçš„validation few-shot examples")
except Exception as e:
    print(f"âš ï¸  æœªæ‰¾åˆ°è‡ªåŠ¨ç”Ÿæˆçš„few-shotï¼Œå°†ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„few-shot: {{e}}")
```

**æ½œåœ¨é—®é¢˜**:
1. **æ–‡ä»¶ä¸å­˜åœ¨æ—¶çš„å¤‡ç”¨æ–¹æ¡ˆä¸å®Œæ•´**ï¼šå¦‚æœ`validation_fewshot.json`ä¸å­˜åœ¨ï¼Œä»£ç ä¼šå›é€€åˆ°é…ç½®æ–‡ä»¶çš„few-shotï¼Œä½†ç”Ÿæˆçš„è„šæœ¬ä¸­é…ç½®æ–‡ä»¶çš„few-shotæ˜¯ç¡¬ç¼–ç çš„ï¼Œä¸æ˜¯åŠ¨æ€è¯»å–
2. **é”™è¯¯å¤„ç†è¿‡äºå®½æ³›**ï¼š`except Exception`ä¼šæ•è·æ‰€æœ‰é”™è¯¯ï¼ŒåŒ…æ‹¬è¯­æ³•é”™è¯¯ï¼Œéš¾ä»¥è°ƒè¯•

**ä¿®å¤æ–¹æ¡ˆ**:
```python
# âœ… æ”¹è¿›çš„åŠ è½½é€»è¾‘
VALIDATION_FEWSHOT_EXAMPLES = []
VALIDATION_FEWSHOT_SOURCE = "none"

# 1. å°è¯•åŠ è½½è‡ªåŠ¨ç”Ÿæˆçš„few-shotï¼ˆæ¥è‡ªæ–­ç‚¹2Aï¼‰
checkpoint_file = Path(__file__).parent.parent / "validation_checkpoints" / "validation_fewshot.json"
if checkpoint_file.exists():
    try:
        with open(checkpoint_file, 'r', encoding='utf-8') as f:
            fewshot_data = json.load(f)
            VALIDATION_FEWSHOT_EXAMPLES = fewshot_data.get('examples', [])
        VALIDATION_FEWSHOT_SOURCE = "checkpoint"
        print(f"âœ“ ä»checkpointåŠ è½½äº† {{len(VALIDATION_FEWSHOT_EXAMPLES)}} ä¸ªfew-shot examples")
    except (json.JSONDecodeError, KeyError) as e:
        print(f"âš ï¸  åŠ è½½checkpoint few-shotå¤±è´¥: {{e}}")

# 2. å¦‚æœcheckpointä¸å­˜åœ¨æˆ–åŠ è½½å¤±è´¥ï¼Œä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„few-shot
if not VALIDATION_FEWSHOT_EXAMPLES:
    # ä»é…ç½®æ–‡ä»¶ç¡¬ç¼–ç çš„few-shotï¼ˆåœ¨ç”Ÿæˆè„šæœ¬æ—¶æ³¨å…¥ï¼‰
    MANUAL_FEWSHOT = {val_cfg.get('few_shot_examples', [])}
    if MANUAL_FEWSHOT:
        VALIDATION_FEWSHOT_EXAMPLES = MANUAL_FEWSHOT
        VALIDATION_FEWSHOT_SOURCE = "config"
        print(f"âœ“ ä»é…ç½®æ–‡ä»¶åŠ è½½äº† {{len(VALIDATION_FEWSHOT_EXAMPLES)}} ä¸ªfew-shot examples")
    else:
        print(f"âš ï¸  è­¦å‘Š: æ²¡æœ‰æ‰¾åˆ°ä»»ä½•few-shot examplesï¼")
        print(f"   è¯·è¿è¡Œ annotate_samples.py --range 21-40 ç”Ÿæˆfew-shot")

print(f"\\nFew-shotæ¥æº: {{VALIDATION_FEWSHOT_SOURCE}}")
```

---

### é—®é¢˜9: ä½¿ç”¨æ–¹æ³•è¯´æ˜ä¸ç¬¦åˆSIMULATIONæµç¨‹

**æ–‡ä»¶**: `automation/stage1_generation/generator.py:639-642`
**å¯¹åº”SIMULATION**: åœºæ™¯1ï¼ˆå®Œæ•´æµç¨‹ï¼‰

**é—®é¢˜æè¿°**:
```python
# generator.pyçš„ä½¿ç”¨è¯´æ˜ï¼ˆtwo_stageæ¨¡å¼ï¼‰
print(f"\\nä½¿ç”¨æ–¹æ³• (two_stage æ¨¡å¼):")
print(f"  1. è®¾ç½®ç¯å¢ƒå˜é‡: export OPENAI_API_KEY=your-key")
print(f"  2. è¿è¡Œç”Ÿæˆ: python {scripts_dir}/rephrase_all.py")
print(f"  3. è¿è¡ŒéªŒè¯: python {scripts_dir}/validate.py")
```

**SIMULATIONå®é™…æµç¨‹**ï¼ˆåœºæ™¯1ï¼Œç¬¬166-519è¡Œï¼‰:
```bash
1. python rephrase_top20.py           # ç”Ÿæˆå‰20ä¸ªæ ·æœ¬
2. python review_top20.py             # æ–­ç‚¹1ï¼šäººå·¥å®¡æ ¸
3. python rephrase_rest.py            # ç”Ÿæˆå‰©ä½™æ ·æœ¬
4. cat top20 + rest > train           # åˆå¹¶ï¼ˆå½“å‰éœ€è¦æ‰‹åŠ¨ï¼‰
5. python annotate_samples.py --range 21-40   # æ–­ç‚¹2A
6. python annotate_samples.py --range 41-80   # æ–­ç‚¹2B
7. python generate_validation_test.py # ç”Ÿæˆæµ‹è¯•è„šæœ¬
8. python validate_prompt_test.py     # æµ‹è¯•å‡†ç¡®ç‡
9. python validate.py                 # æ–­ç‚¹3ï¼šè‡ªåŠ¨éªŒè¯
```

**å½±å“**:
- ğŸŸ  ç”¨æˆ·æŒ‰ç…§è¯´æ˜æ“ä½œä¼šè·³è¿‡æ‰€æœ‰æ–­ç‚¹
- ğŸŸ  æ— æ³•è¿›è¡Œäººå·¥è´¨é‡æ§åˆ¶
- ğŸŸ  å¤±å»two-stageæ¨¡å¼çš„æ ¸å¿ƒä¼˜åŠ¿

**ä¿®å¤æ–¹æ¡ˆ**:
```python
if gen_strategy == 'two_stage':
    print(f"\\nä½¿ç”¨æ–¹æ³• (two_stage æ¨¡å¼ - åŒ…å«3ä¸ªäººå·¥å®¡æ ¸æ–­ç‚¹):")
    print(f"  ğŸ“ æ–­ç‚¹1: å®¡æ ¸å‰20ä¸ªæ ·æœ¬")
    print(f"    1. python {scripts_dir}/rephrase_top20.py")
    print(f"    2. python {scripts_dir.parent.parent.parent}/automation/stage1_generation/tools/review_top20.py")
    print(f"")
    print(f"  ğŸ“ ç”Ÿæˆå‰©ä½™æ•°æ®:")
    print(f"    3. python {scripts_dir}/rephrase_rest.py")
    print(f"")
    print(f"  ğŸ“ æ–­ç‚¹2A: å¤„ç†æ ·æœ¬21-40ï¼ˆç”Ÿæˆvalidation few-shotï¼‰")
    print(f"    4. python {scripts_dir.parent.parent.parent}/automation/stage1_generation/tools/annotate_samples.py --range 21-40")
    print(f"")
    print(f"  ğŸ“ æ–­ç‚¹2B: å¤„ç†æ ·æœ¬41-80ï¼ˆç”Ÿæˆtest setï¼‰")
    print(f"    5. python {scripts_dir.parent.parent.parent}/automation/stage1_generation/tools/annotate_samples.py --range 41-80")
    print(f"    6. python {scripts_dir.parent.parent.parent}/automation/stage1_generation/tools/generate_validation_test.py")
    print(f"    7. python {scripts_dir}/validate_prompt_test.py  # æµ‹è¯•å‡†ç¡®ç‡éœ€â‰¥95%")
    print(f"")
    print(f"  ğŸ“ æ–­ç‚¹3: è‡ªåŠ¨éªŒè¯å…¨éƒ¨400ä¸ªæ ·æœ¬")
    print(f"    8. python {scripts_dir}/validate.py")
    print(f"")
    print(f"  è¯¦ç»†æµç¨‹è¯·å‚è€ƒ: automation/COMPLETE_PIPELINE_SIMULATION.md")
```

---

## ğŸŸ¡ P2 ä¸­ä¼˜å…ˆçº§é—®é¢˜

### é—®é¢˜10: APIé…ç½®ç¡¬ç¼–ç æ³„éœ²é£é™©

**æ–‡ä»¶**: `automation/stage1_generation/generator.py:110-121`

**é—®é¢˜æè¿°**:
```python
api_key = self.config['generation'].get('api_key', 'sk-eWSYPo0CvhRYgcJs55B0C3F00aC74f6e95F47c1f4772292c')
base_url = self.config['generation'].get('base_url', 'https://api2.aigcbest.top/v1')
```

ç¡¬ç¼–ç çš„é»˜è®¤API keyå¯èƒ½å¯¼è‡´ï¼š
- å®‰å…¨é£é™©ï¼ˆå¦‚æœä»£ç å…¬å¼€ï¼‰
- ä¸å¤Ÿçµæ´»ï¼ˆæ— æ³•ä½¿ç”¨ç¯å¢ƒå˜é‡ï¼‰

**ä¿®å¤æ–¹æ¡ˆ**:
```python
# âœ… ä¼˜å…ˆä½¿ç”¨é…ç½®æ–‡ä»¶ï¼Œå…¶æ¬¡ç¯å¢ƒå˜é‡ï¼Œæœ€åæ‰æ˜¯é»˜è®¤å€¼
import os

api_key = (
    self.config['generation'].get('api_key') or
    os.environ.get('OPENAI_API_KEY') or
    ''  # ç©ºå­—ç¬¦ä¸²ï¼Œå¼ºåˆ¶ç”¨æˆ·æä¾›
)

if not api_key:
    raise ValueError("API keyæœªé…ç½®ï¼è¯·åœ¨é…ç½®æ–‡ä»¶ä¸­è®¾ç½®generation.api_keyæˆ–è®¾ç½®OPENAI_API_KEYç¯å¢ƒå˜é‡")

base_url = (
    self.config['generation'].get('base_url') or
    os.environ.get('OPENAI_API_BASE') or
    'https://api.openai.com/v1'
)
```

---

### é—®é¢˜11: é”™è¯¯å¤„ç†è¿‡äºå®½æ³›

**æ–‡ä»¶**: å¤šä¸ªç”Ÿæˆçš„è„šæœ¬ï¼ˆrephrase_*.py, validate.pyï¼‰

**é—®é¢˜æè¿°**:
```python
# generator.py:290-294ç”Ÿæˆçš„é”™è¯¯å¤„ç†
except Exception as e:
    print(f"\\nå¤„ç†ç¬¬ {{i}} æ¡æ•°æ®æ—¶å‡ºé”™: {{e}}")
    # å‡ºé”™æ—¶ä½¿ç”¨åŸå§‹æ•°æ®
    out_file.write(json.dumps(data[i], ensure_ascii=False) + "\\n")
```

**æ½œåœ¨é—®é¢˜**:
- æ•è·æ‰€æœ‰å¼‚å¸¸ï¼ŒåŒ…æ‹¬KeyboardInterruptã€SystemExit
- æ— æ³•åŒºåˆ†ç½‘ç»œé”™è¯¯ã€APIé”™è¯¯ã€æ•°æ®æ ¼å¼é”™è¯¯
- éš¾ä»¥è°ƒè¯•å’Œå®šä½é—®é¢˜

**ä¿®å¤æ–¹æ¡ˆ**:
```python
# âœ… æ›´ç²¾ç»†çš„é”™è¯¯å¤„ç†
except KeyboardInterrupt:
    print(f"\\nç”¨æˆ·ä¸­æ–­ï¼Œå·²å¤„ç† {{i}}/{{len(data)}} æ¡æ•°æ®")
    out_file.close()
    raise
except (APIError, APIConnectionError, RateLimitError) as e:
    # APIç›¸å…³é”™è¯¯ï¼šé‡è¯•æˆ–è®°å½•
    print(f"\\nå¤„ç†ç¬¬ {{i}} æ¡æ•°æ®æ—¶APIå‡ºé”™: {{e}}")
    retry_count = 0
    while retry_count < 3:
        try:
            # é‡è¯•é€»è¾‘...
            break
        except:
            retry_count += 1
            time.sleep(2 ** retry_count)
    else:
        # é‡è¯•å¤±è´¥ï¼Œä½¿ç”¨åŸå§‹æ•°æ®
        out_file.write(json.dumps(data[i], ensure_ascii=False) + "\\n")
except (KeyError, IndexError, ValueError) as e:
    # æ•°æ®æ ¼å¼é”™è¯¯ï¼šè®°å½•å¹¶ä½¿ç”¨åŸå§‹æ•°æ®
    print(f"\\nå¤„ç†ç¬¬ {{i}} æ¡æ•°æ®æ—¶æ•°æ®æ ¼å¼å‡ºé”™: {{e}}")
    print(f"  æ•°æ®å†…å®¹: {{data[i]}}")
    out_file.write(json.dumps(data[i], ensure_ascii=False) + "\\n")
except Exception as e:
    # æœªçŸ¥é”™è¯¯ï¼šè®°å½•è¯¦ç»†ä¿¡æ¯
    print(f"\\nå¤„ç†ç¬¬ {{i}} æ¡æ•°æ®æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {{e}}")
    import traceback
    traceback.print_exc()
    out_file.write(json.dumps(data[i], ensure_ascii=False) + "\\n")
```

---

### é—®é¢˜12: ç¼ºå°‘è¿›åº¦ä¿å­˜å’Œæ–­ç‚¹ç»­ä¼ 

**æ–‡ä»¶**: æ‰€æœ‰ç”Ÿæˆè„šæœ¬ï¼ˆrephrase_*.pyï¼‰

**é—®é¢˜æè¿°**:
å¦‚æœæ•°æ®ç”Ÿæˆè¿‡ç¨‹ä¸­æ–­ï¼ˆç½‘ç»œé”™è¯¯ã€APIé™æµã€ç”¨æˆ·ä¸­æ–­ï¼‰ï¼Œå½“å‰æ²¡æœ‰ä¿å­˜è¿›åº¦ï¼Œéœ€è¦ä»å¤´å¼€å§‹ã€‚å¯¹äº400æ¡æ•°æ®ï¼Œå¯èƒ½æµªè´¹å¤§é‡APIè°ƒç”¨ã€‚

**å½±å“**:
- ğŸŸ¡ ç½‘ç»œä¸ç¨³å®šæ—¶éš¾ä»¥å®Œæˆæ•°æ®ç”Ÿæˆ
- ğŸŸ¡ APIé™æµæ—¶æ— æ³•ç»­ä¼ 
- ğŸŸ¡ æµªè´¹æ—¶é—´å’ŒAPIé…é¢

**ä¿®å¤æ–¹æ¡ˆ**:
```python
# âœ… æ·»åŠ è¿›åº¦ä¿å­˜
import json
import os

progress_file = os.path.join(dataset_dir, ".progress_{strategy}.json")

# åŠ è½½å·²å¤„ç†çš„ç´¢å¼•
processed_indices = set()
if os.path.exists(progress_file):
    with open(progress_file, 'r') as f:
        processed_indices = set(json.load(f))
    print(f"âœ“ ä»è¿›åº¦æ–‡ä»¶æ¢å¤: å·²å¤„ç† {{len(processed_indices)}} æ¡æ•°æ®")

# å¤„ç†æ•°æ®
for i in tqdm(range(len(data))):
    if i in processed_indices:
        continue  # è·³è¿‡å·²å¤„ç†çš„æ•°æ®

    # ... å¤„ç†é€»è¾‘ ...

    # ä¿å­˜è¿›åº¦
    processed_indices.add(i)
    if i % 10 == 0:  # æ¯10æ¡ä¿å­˜ä¸€æ¬¡è¿›åº¦
        with open(progress_file, 'w') as f:
            json.dump(list(processed_indices), f)

# å®Œæˆååˆ é™¤è¿›åº¦æ–‡ä»¶
if os.path.exists(progress_file):
    os.remove(progress_file)
```

---

## ğŸŸ¢ P3 ä½ä¼˜å…ˆçº§é—®é¢˜

### é—®é¢˜13: batch_toolsæ–‡ä»¶æƒé™ä¸æ ‡å‡†

**æ–‡ä»¶**: `automation/stage1_generation/batch_tools/*.py`

**é—®é¢˜**:
```bash
-rwx--x--x 1 ubuntu ubuntu 6991 Dec 29 04:33 compare_experiments.py
```

ç¼ºå°‘ç»„å’Œå…¶ä»–ç”¨æˆ·çš„è¯»æƒé™ã€‚

**ä¿®å¤**:
```bash
chmod 755 automation/stage1_generation/batch_tools/*.py
```

---

### é—®é¢˜14: READMEä½¿ç”¨è¯´æ˜ä¸SIMULATIONä¸ç¬¦

**æ–‡ä»¶**: `automation/stage1_generation/generator.py:644-763` (generate_readmeå‡½æ•°)

**é—®é¢˜**:
ç”Ÿæˆçš„README.mdä½¿ç”¨è¯´æ˜ç®€åŒ–ï¼Œæ²¡æœ‰åŒ…å«å®Œæ•´çš„æ–­ç‚¹æµç¨‹ï¼Œä¸SIMULATIONæ–‡æ¡£ä¸ä¸€è‡´ã€‚

**ä¿®å¤æ–¹æ¡ˆ**:
åœ¨READMEä¸­æ·»åŠ è¯¦ç»†çš„two-stageæµç¨‹è¯´æ˜ï¼Œå¹¶å¼•ç”¨SIMULATIONæ–‡æ¡£ã€‚

---

## âœ… æ­£ç¡®å®ç°çš„åŠŸèƒ½

ä»¥ä¸‹æ ¸å¿ƒåŠŸèƒ½å·²æ­£ç¡®å®ç°ï¼š

1. **Batchæ–¹æ¡ˆçš„å‚æ•°æŒ‡çº¹å»é‡** âœ…
   `experiment_manager_batch.py:20-56`

2. **validate.pyæ’é™¤21-40æ ·æœ¬** âœ…
   `generator.py:422-430`ï¼ˆé€»è¾‘æ­£ç¡®ï¼Œä½†ç»Ÿè®¡éœ€ä¿®å¤ï¼‰

3. **direct_allæ¨¡å¼è·³è¿‡éªŒè¯è„šæœ¬** âœ…
   `generator.py:598-609`

4. **æ•°æ®é›†å­ç›®å½•åˆ›å»º** âœ…
   `generator.py:559-564`

5. **Few-shotå ä½ç¬¦æ›¿æ¢æœºåˆ¶** âœ…
   `generator.py:235-236`

6. **Validation few-shotè‡ªåŠ¨åŠ è½½** âœ…
   `generator.py:329-342`ï¼ˆéœ€æ”¹è¿›é”™è¯¯å¤„ç†ï¼‰

---

## ğŸ”§ ä¿®å¤ä¼˜å…ˆçº§å’Œè·¯çº¿å›¾

### Phase 1: ç´§æ€¥ä¿®å¤ï¼ˆP0é—®é¢˜ï¼Œé˜»å¡æµç¨‹ï¼‰

**æ—¶é—´ä¼°è®¡**: 2-4å°æ—¶
**ç›®æ ‡**: ä½¿two-stage pipelineå¯è¿è¡Œ

- [ ] **é—®é¢˜1**: ä¿®å¤annotate_samples.pyæ•°æ®è·¯å¾„
- [ ] **é—®é¢˜2**: åœ¨rephrase_rest.pyä¸­æ·»åŠ è‡ªåŠ¨åˆå¹¶é€»è¾‘
- [ ] **é—®é¢˜3**: æ·»åŠ top_pç­‰APIå‚æ•°
- [ ] **é—®é¢˜4**: ä¿®å¤validate.pyç»Ÿè®¡é€»è¾‘
- [ ] **é—®é¢˜5**: ä¿®å¤review_top20.pyç›´æ¥è¦†ç›–åŸæ–‡ä»¶

### Phase 2: è´¨é‡æ”¹è¿›ï¼ˆP1é—®é¢˜ï¼Œå½±å“ä½“éªŒï¼‰

**æ—¶é—´ä¼°è®¡**: 3-5å°æ—¶
**ç›®æ ‡**: æå‡ç”¨æˆ·ä½“éªŒå’Œæ•°æ®è´¨é‡

- [ ] **é—®é¢˜6**: æ”¹è¿›few-shotæ³¨å…¥ä½ç½®
- [ ] **é—®é¢˜7**: ç»Ÿä¸€æ•°æ®é›†ç›®å½•å‘½åé€»è¾‘
- [ ] **é—®é¢˜8**: æ”¹è¿›validation few-shotåŠ è½½
- [ ] **é—®é¢˜9**: æ›´æ–°ä½¿ç”¨è¯´æ˜ç¬¦åˆSIMULATION

### Phase 3: ä»£ç è´¨é‡ï¼ˆP2-P3é—®é¢˜ï¼‰

**æ—¶é—´ä¼°è®¡**: 2-3å°æ—¶
**ç›®æ ‡**: æå‡ä»£ç è´¨é‡å’Œå¯ç»´æŠ¤æ€§

- [ ] **é—®é¢˜10**: ç§»é™¤ç¡¬ç¼–ç APIé…ç½®
- [ ] **é—®é¢˜11**: æ”¹è¿›é”™è¯¯å¤„ç†
- [ ] **é—®é¢˜12**: æ·»åŠ è¿›åº¦ä¿å­˜
- [ ] **é—®é¢˜13**: ä¿®å¤æ–‡ä»¶æƒé™
- [ ] **é—®é¢˜14**: æ›´æ–°README

---

## ğŸ§ª æµ‹è¯•éªŒè¯è®¡åˆ’

### 1. Two-Stageå®Œæ•´æµç¨‹æµ‹è¯•

```bash
# å‡†å¤‡æµ‹è¯•ç¯å¢ƒ
cd /home/ubuntu/LLM-inference/jikai-project/Synthetic_Data_for_ZO
export OPENAI_API_KEY="your-key"

# ç”Ÿæˆè„šæœ¬
python automation/stage1_generation/generator.py \
    automation/configs/examples/stage1_full_example_copa.yaml

cd Data_v2/synthetic/_shared/Copa/temp09_topp10_gpt4o/scripts/

# æ–­ç‚¹1
python rephrase_top20.py
# âœ… æ£€æŸ¥: ../Copa/copa_train_top20.jsonl å­˜åœ¨ä¸”æœ‰20æ¡æ•°æ®

cp ../../../../automation/stage1_generation/tools/review_top20.py .
python review_top20.py
# âœ… æ£€æŸ¥:
#   - ../Copa/copa_train_top20.jsonl è¢«rejection samplingæ›´æ–°
#   - ../validation_checkpoints/top20_fewshot.json å­˜åœ¨
#   - rephrase_rest.py ä¸­æ³¨å…¥äº†FEWSHOT_EXAMPLES

# ç”Ÿæˆå‰©ä½™æ•°æ®
python rephrase_rest.py
# âœ… æ£€æŸ¥:
#   - ../Copa/copa_train_rest.jsonl å­˜åœ¨ä¸”æœ‰380æ¡æ•°æ®
#   - ../Copa/copa_train.jsonl è‡ªåŠ¨åˆå¹¶å®Œæˆï¼ˆ400æ¡ï¼‰

# æ–­ç‚¹2A
cp ../../../../automation/stage1_generation/tools/annotate_samples.py .
python annotate_samples.py --range 21-40
# âœ… æ£€æŸ¥:
#   - èƒ½æ­£ç¡®æ‰¾åˆ°å¹¶è¯»å– ../Copa/copa_train.jsonl
#   - ../validation_checkpoints/validation_fewshot.json å­˜åœ¨
#   - ../validation_checkpoints/samples_21_40_validated.jsonl å­˜åœ¨

# æ–­ç‚¹2B
python annotate_samples.py --range 41-80
# âœ… æ£€æŸ¥:
#   - ../validation_checkpoints/validation_test_set.json å­˜åœ¨ä¸”æœ‰40æ¡æµ‹è¯•æ ·æœ¬

# æµ‹è¯•validation prompt
cp ../../../../automation/stage1_generation/tools/generate_validation_test.py .
python generate_validation_test.py
# âœ… æ£€æŸ¥: validate_prompt_test.py ç”Ÿæˆ

python validate_prompt_test.py
# âœ… æ£€æŸ¥: å‡†ç¡®ç‡ â‰¥ 95%

# æ–­ç‚¹3
python validate.py
# âœ… æ£€æŸ¥:
#   - éªŒè¯æ ·æœ¬æ•°æ­£ç¡®ï¼ˆ320æ¡ï¼Œæ’é™¤1-80ï¼‰
#   - ç»Ÿè®¡å‡†ç¡®ç‡æ­£ç¡®
#   - æœ€ç»ˆæ•°æ®é›†å®Œæ•´ï¼ˆtrain/validation/testï¼‰
```

### 2. Direct-Allæ¨¡å¼æµ‹è¯•

```bash
python automation/stage1_generation/generator.py \
    automation/configs/examples/stage1_direct_all_copa.yaml

cd Data_v2/synthetic/_shared/Copa/temp07_topp10_gpt4o/scripts/
python rephrase_all.py
# âœ… æ£€æŸ¥:
#   - ../Copa/copa_train.jsonl å­˜åœ¨ä¸”æœ‰400æ¡æ•°æ®
#   - æ²¡æœ‰ç”Ÿæˆvalidate.py
```

### 3. Batchå»é‡æµ‹è¯•

```bash
# è¿è¡Œä¸¤æ¬¡ç›¸åŒå‚æ•°é…ç½®
python automation/stage1_generation/generator.py config1.yaml
python automation/stage1_generation/generator.py config2.yaml  # ç›¸åŒå‚æ•°

# âœ… æ£€æŸ¥:
#   - ç¬¬äºŒæ¬¡è¿è¡Œå¤ç”¨äº†ç¬¬ä¸€æ¬¡çš„ç‰©ç†æ•°æ®
#   - _shared/ä¸­åªæœ‰ä¸€ä»½ç‰©ç†æ•°æ®
#   - ä¸¤ä¸ªbatché€šè¿‡ç¬¦å·é“¾æ¥æŒ‡å‘åŒä¸€ç‰©ç†æ•°æ®
```

---

## ğŸ“Š å½±å“åˆ†æ

| é—®é¢˜ID | å½±å“èŒƒå›´ | é˜»å¡åœºæ™¯ | æ•°æ®è´¨é‡å½±å“ |
|-------|---------|---------|-------------|
| P0-1 | Two-Stageå…¨æµç¨‹ | æ–­ç‚¹2A/2B | âš ï¸ é«˜ |
| P0-2 | Two-Stageå…¨æµç¨‹ | æ–­ç‚¹3 | âš ï¸ é«˜ |
| P0-3 | æ‰€æœ‰åœºæ™¯ | Batchå»é‡ | âš ï¸ é«˜ |
| P0-4 | Two-StageéªŒè¯ | ç»Ÿè®¡å‡†ç¡®æ€§ | âš ï¸ ä¸­ |
| P0-5 | Two-Stageå…¨æµç¨‹ | æ–­ç‚¹1æ•ˆæœ | âš ï¸ é«˜ |
| P1-6 | Two-Stageç”Ÿæˆ | Few-shotè´¨é‡ | âš ï¸ ä¸­ |
| P1-7 | å·¥å…·äº’æ“ä½œ | æ–‡ä»¶æŸ¥æ‰¾ | âš ï¸ ä½ |
| P1-8 | Validation | å¤‡ç”¨æ–¹æ¡ˆ | âš ï¸ ä½ |
| P1-9 | ç”¨æˆ·ä½“éªŒ | æµç¨‹ç†è§£ | âš ï¸ æ—  |

---

## ğŸ’¡ å»ºè®®

1. **ç«‹å³ä¿®å¤P0é—®é¢˜**: è¿™5ä¸ªé—®é¢˜å¯¼è‡´pipelineå®Œå…¨æ— æ³•è¿è¡Œ
2. **æ·»åŠ é›†æˆæµ‹è¯•**: åˆ›å»ºç«¯åˆ°ç«¯æµ‹è¯•è„šæœ¬éªŒè¯å®Œæ•´æµç¨‹
3. **æ”¹è¿›æ–‡æ¡£**: ç¡®ä¿READMEå’ŒSIMULATIONæ–‡æ¡£ä¸€è‡´
4. **æ·»åŠ å•å…ƒæµ‹è¯•**: å¯¹å…³é”®å‡½æ•°ï¼ˆå¦‚è·¯å¾„è§£æã€æ•°æ®åˆå¹¶ï¼‰æ·»åŠ å•å…ƒæµ‹è¯•
5. **ä»£ç å®¡æŸ¥**: å»ºç«‹ä»£ç å®¡æŸ¥æµç¨‹ï¼Œé˜²æ­¢ç±»ä¼¼é—®é¢˜å†æ¬¡å‡ºç°

---

## ğŸ“š é™„å½•

### A. æµ‹è¯•æ•°æ®å‡†å¤‡

```bash
# åˆ›å»ºæœ€å°æµ‹è¯•æ•°æ®é›†ï¼ˆ10æ¡æ•°æ®ï¼‰
cd Data/original/Copa
head -10 copa_train.jsonl > copa_train_mini.jsonl

# ä¿®æ”¹é…ç½®æ–‡ä»¶ä½¿ç”¨miniæ•°æ®é›†
vim automation/configs/test/copa_mini.yaml
# dataset.input_path: "Data/original/Copa/copa_train_mini.jsonl"
```

### B. è°ƒè¯•æŠ€å·§

```bash
# åœ¨æ¯ä¸ªæ–­ç‚¹æ·»åŠ è¯¦ç»†æ—¥å¿—
set -x  # å¯ç”¨shellè°ƒè¯•æ¨¡å¼

# æ£€æŸ¥æ•°æ®æ–‡ä»¶
wc -l ../Copa/*.jsonl
jq . ../Copa/copa_train.jsonl | head -20  # æ£€æŸ¥JSONæ ¼å¼

# æ£€æŸ¥ç¬¦å·é“¾æ¥
ls -la Data_v2/synthetic/batch_*
readlink Data_v2/synthetic/batch_*/Copa/*
```

### C. å¸¸è§é”™è¯¯å’Œè§£å†³æ–¹æ¡ˆ

| é”™è¯¯ä¿¡æ¯ | å¯èƒ½åŸå›  | è§£å†³æ–¹æ¡ˆ |
|---------|---------|---------|
| `FileNotFoundError: copa_train.jsonl` | æœªåˆå¹¶æ•°æ® | è¿è¡Œåˆå¹¶å‘½ä»¤æˆ–ä¿®å¤è‡ªåŠ¨åˆå¹¶é€»è¾‘ |
| `KeyError: 'dataset_name'` | é…ç½®æ–‡ä»¶ç¼ºå°‘å­—æ®µ | æ·»åŠ dataset_nameå­—æ®µ |
| `API rate limit` | APIè°ƒç”¨è¿‡å¿« | æ·»åŠ é‡è¯•é€»è¾‘æˆ–é™ä½å¹¶å‘ |

---

**æŠ¥å‘Šå®Œæˆæ—¶é—´**: 2026-01-01
**ä¸‹æ¬¡å®¡æŸ¥å»ºè®®**: Phase 1ä¿®å¤å®Œæˆåé‡æ–°æµ‹è¯•
