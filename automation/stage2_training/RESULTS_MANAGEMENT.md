# è®­ç»ƒç»“æœç®¡ç†ç³»ç»Ÿ

## ğŸ”´ æ ¸å¿ƒè®¾è®¡ç†å¿µï¼šé˜¶æ®µ1å’Œé˜¶æ®µ2çš„å®éªŒç›®çš„ç‹¬ç«‹

### **ä¸ºä»€ä¹ˆè¦åˆ†å¼€ï¼Ÿ**

**é˜¶æ®µ1ï¼ˆæ•°æ®ç”Ÿæˆï¼‰çš„å®éªŒç›®çš„**ï¼š
- å›ç­”ï¼š"ä¸ºä»€ä¹ˆç”Ÿæˆè¿™ä¸ªæ•°æ®ï¼Ÿ"
- ç¤ºä¾‹ï¼š`prompt_engineering`, `temperature_study`, `data_quality_optimization`
- å­˜å‚¨ä½ç½®ï¼š`Data_v2/synthetic/{æ•°æ®ç”Ÿæˆç›®çš„}/`

**é˜¶æ®µ2ï¼ˆæ¨¡å‹è®­ç»ƒï¼‰çš„å®éªŒç›®çš„**ï¼š
- å›ç­”ï¼š"ä¸ºä»€ä¹ˆè¿›è¡Œè¿™ä¸ªè®­ç»ƒï¼Ÿ"
- ç¤ºä¾‹ï¼š`model_comparison`, `hyperparameter_tuning`, `baseline_comparison`
- å­˜å‚¨ä½ç½®ï¼š`Results_v2/{è®­ç»ƒç›®çš„}/`

### **å…¸å‹åœºæ™¯**

```
ã€åœºæ™¯ã€‘ï¼šä½¿ç”¨åŒä¸€ä¸ªæ•°æ®é›†è¿›è¡Œå¤šç§ä¸åŒçš„è®­ç»ƒå®éªŒ

æ•°æ®é›†ï¼ˆé˜¶æ®µ1ï¼‰ï¼š
Data_v2/synthetic/prompt_engineering/copa_mezo_v1/
â†‘ æ•°æ®ç”Ÿæˆç›®çš„ï¼šæµ‹è¯•promptå¯¹æ•°æ®è´¨é‡çš„å½±å“

è®­ç»ƒå®éªŒï¼ˆé˜¶æ®µ2ï¼‰ï¼š
â”œâ”€â”€ Results_v2/model_comparison/        â† è®­ç»ƒç›®çš„ï¼šå¯¹æ¯”ä¸åŒæ¨¡å‹
â”œâ”€â”€ Results_v2/hyperparameter_tuning/   â† è®­ç»ƒç›®çš„ï¼šè°ƒæ•´å­¦ä¹ ç‡
â”œâ”€â”€ Results_v2/baseline_comparison/     â† è®­ç»ƒç›®çš„ï¼šä¸åŸå§‹æ•°æ®å¯¹æ¯”
â””â”€â”€ Results_v2/ablation_study/          â† è®­ç»ƒç›®çš„ï¼šæ¶ˆèå®éªŒ
```

**å…³é”®ç‚¹**ï¼š
- âœ… åŒä¸€ä¸ªæ•°æ®é›†ï¼ˆ`prompt_engineering/copa_mezo_v1`ï¼‰å¯ä»¥ç”¨äºå¤šä¸ªä¸åŒçš„è®­ç»ƒå®éªŒ
- âœ… æ¯ä¸ªè®­ç»ƒå®éªŒæœ‰è‡ªå·±çš„ç›®çš„ï¼Œç»“æœæŒ‰è®­ç»ƒç›®çš„åˆ†ç±»
- âŒ å¦‚æœä¸åˆ†å¼€ï¼Œæ‰€æœ‰ç»“æœéƒ½ä¼šæ··åœ¨`prompt_engineering`ç›®å½•ä¸‹ï¼Œæ— æ³•åŒºåˆ†

---

## ğŸ“‹ ç›®å½•ç»“æ„

### **æ–°çš„Results_v2ç»“æ„**

```
Results_v2/
â””â”€â”€ {experiment_purpose}/           # ğŸ†• å®éªŒç›®çš„åˆ†ç±»ï¼ˆä¸Data_v2å¯¹é½ï¼‰
    â””â”€â”€ {Model}/
        â””â”€â”€ {Task}_{Method}_{DataType}_{LR}/
            â””â”€â”€ {Timestamp}/
                â”œâ”€â”€ experiment_config.yaml  # å®éªŒé…ç½®
                â”œâ”€â”€ {lr}_train.out         # è®­ç»ƒè¾“å‡º
                â”œâ”€â”€ {lr}_train.err         # é”™è¯¯è¾“å‡º
                â””â”€â”€ ...                    # æ¨¡å‹checkpointç­‰
```

### **ç›®å½•è¯´æ˜**

1. **experiment_purpose**: å®éªŒç›®çš„åˆ†ç±»
   - ä¸Data_v2çš„experiment_purposeå¯¹åº”
   - ä¾‹å¦‚ï¼š`prompt_engineering`, `temperature_study`, `model_comparison`

2. **Model**: æ¨¡å‹åç§°
   - ä¾‹å¦‚ï¼š`meta-llama/Llama-3.2-1B`, `mistralai/Mistral-Nemo-Base-2407`

3. **Task_Method_DataType_LR**: å®éªŒæ ‡è¯†
   - Task: ä»»åŠ¡åç§°ï¼ˆCopa, BOOLQ, CBç­‰ï¼‰
   - Method: è®­ç»ƒæ–¹æ³•ï¼ˆzo, fo_full, fo_loraï¼‰
   - DataType: æ•°æ®ç±»å‹ï¼ˆoriginal, syntheticç­‰ï¼‰
   - LR: å­¦ä¹ ç‡ï¼ˆæ ¼å¼åŒ–ï¼Œå¦‚`1_7`è¡¨ç¤º1e-7ï¼‰

4. **Timestamp**: æ—¶é—´æˆ³ï¼ˆæ ¼å¼ï¼šYYYYMMDD_HHMMSSï¼‰
   - åŒä¸€é…ç½®çš„å¤šæ¬¡è¿è¡Œä¼šåˆ›å»ºä¸åŒçš„æ—¶é—´æˆ³ç›®å½•

---

## ğŸ¯ æ ¸å¿ƒåŠŸèƒ½

### **1. è®­ç»ƒå®éªŒç›®çš„åˆ†ç±»**

è®­ç»ƒç»“æœæŒ‰**è®­ç»ƒå®éªŒç›®çš„**åˆ†ç±»ï¼ˆä¸æ•°æ®ç”Ÿæˆç›®çš„ç‹¬ç«‹ï¼‰ï¼š

```yaml
# é…ç½®æ–‡ä»¶
experiment:
  purpose: "hyperparameter_tuning"  # ğŸ”´ è®­ç»ƒç›®çš„ï¼ç»“æœä¿å­˜åˆ°: Results_v2/hyperparameter_tuning/

data:
  path: "Data_v2/synthetic/prompt_engineering/copa_mezo_v1/Copa"
  #                        â†‘ æ•°æ®ç”Ÿæˆç›®çš„ï¼ˆä¸è®­ç»ƒç›®çš„ä¸åŒï¼‰
```

### **2. å¿…é¡»æ˜¾å¼æŒ‡å®šè®­ç»ƒç›®çš„**

`experiment.purpose`å¿…é¡»æ˜¾å¼æŒ‡å®šï¼Œå¦‚æœæœªæŒ‡å®šåˆ™ä½¿ç”¨é»˜è®¤å€¼`uncategorized`ï¼š

```yaml
# âœ… æ¨èï¼šæ˜¾å¼æŒ‡å®š
experiment:
  purpose: "model_comparison"

# âš ï¸  å¦‚æœä¸æŒ‡å®šï¼Œç»“æœä¼šä¿å­˜åˆ° Results_v2/uncategorized/
```

**æ¨èçš„è®­ç»ƒå®éªŒç›®çš„ç±»åˆ«**ï¼š
- `baseline_comparison` - ä¸baselineå¯¹æ¯”
- `model_comparison` - å¯¹æ¯”ä¸åŒæ¨¡å‹
- `hyperparameter_tuning` - è¶…å‚æ•°è°ƒä¼˜
- `ablation_study` - æ¶ˆèå®éªŒ
- `prompt_effectiveness` - æµ‹è¯•promptæ•ˆæœ
- `data_quality_impact` - æµ‹è¯•æ•°æ®è´¨é‡å½±å“
- `scaling_study` - æ‰©å±•æ€§ç ”ç©¶

### **3. å®Œæ•´å…ƒæ•°æ®è¿½æº¯**

æ¯ä¸ªè®­ç»ƒå®éªŒè‡ªåŠ¨ä¿å­˜å®Œæ•´é…ç½®ï¼š

```yaml
# experiment_config.yaml
timestamp: "20251226_143000"
experiment_purpose: "prompt_engineering"
model: "meta-llama/Llama-3.2-1B"
task: "Copa"
method: "zo"
data:
  path: "Data_v2/synthetic/prompt_engineering/copa_mezo_v1/Copa"
hyperparameters:
  learning_rate: 1e-6
  batch_size: 16
  steps: 20000
  seed: 0
training_info:
  env_vars: {...}
  command: "..."
  out_file: "..."
  err_file: "..."
```

---

## ğŸ“– ä½¿ç”¨æŒ‡å—

### **åœºæ™¯1ï¼šè¶…å‚æ•°è°ƒä¼˜ï¼ˆä½¿ç”¨åˆæˆæ•°æ®ï¼‰**

```yaml
# training_config.yaml
experiment:
  purpose: "hyperparameter_tuning"  # ğŸ”´ è®­ç»ƒç›®çš„ï¼šè°ƒä¼˜è¶…å‚æ•°
  description: "ä½¿ç”¨copa_mezo_v1æ•°æ®æµ‹è¯•ä¸åŒå­¦ä¹ ç‡"

model: "meta-llama/Llama-3.2-1B"
task: "Copa"
method: "zo"

data:
  path: "Data_v2/synthetic/prompt_engineering/copa_mezo_v1/Copa"  # ğŸ†• ç›´æ¥æŒ‡å®šè·¯å¾„

hyperparameters:
  learning_rate: [1e-6, 5e-7, 2e-7, 1e-7]
  batch_size: 16
  steps: 20000
  seed: 0
```

**è¿è¡Œè®­ç»ƒ**ï¼š
```bash
python automation/stage2_training/trainer.py training_config.yaml
```

**ç»“æœä¿å­˜åˆ°**ï¼š
```
Results_v2/hyperparameter_tuning/meta-llama/Llama-3.2-1B/
                â†‘ æŒ‰è®­ç»ƒç›®çš„åˆ†ç±»ï¼ˆä¸æ˜¯æ•°æ®ç”Ÿæˆç›®çš„ï¼‰
â”œâ”€â”€ Copa_zo_copa_mezo_v1_1_6/
â”‚   â””â”€â”€ 20251226_143000/
â”œâ”€â”€ Copa_zo_copa_mezo_v1_5_7/
â”‚   â””â”€â”€ 20251226_143000/
â”œâ”€â”€ Copa_zo_copa_mezo_v1_2_7/
â”‚   â””â”€â”€ 20251226_143000/
â””â”€â”€ Copa_zo_copa_mezo_v1_1_7/
    â””â”€â”€ 20251226_143000/
```

### **åœºæ™¯2ï¼šæ¨¡å‹å¯¹æ¯”ï¼ˆä½¿ç”¨ç›¸åŒæ•°æ®ï¼‰**

```yaml
# training_config.yaml
experiment:
  purpose: "model_comparison"  # ğŸ”´ è®­ç»ƒç›®çš„ï¼šå¯¹æ¯”ä¸åŒæ¨¡å‹
  description: "åœ¨copa_mezo_v1æ•°æ®ä¸Šå¯¹æ¯”Llamaå’ŒMistral"

model: "mistralai/Mistral-Nemo-Base-2407"  # ğŸ”§ æµ‹è¯•ä¸åŒæ¨¡å‹
task: "Copa"
method: "zo"

data:
  path: "Data_v2/synthetic/prompt_engineering/copa_mezo_v1/Copa"
  #                        â†‘ æ•°æ®æ¥è‡ªprompt_engineeringå®éªŒ
  #                        â†‘ ä½†è®­ç»ƒç›®çš„æ˜¯model_comparison

hyperparameters:
  learning_rate: 5e-7  # ä½¿ç”¨å·²çŸ¥æœ€ä½³å­¦ä¹ ç‡
  batch_size: 16
  steps: 20000
  seed: 0
```

**ç³»ç»Ÿè¡Œä¸º**ï¼š
- æ•°æ®æ¥æºï¼š`Data_v2/synthetic/prompt_engineering/...`
- è®­ç»ƒç›®çš„ï¼š`model_comparison`ï¼ˆä¸æ•°æ®ç”Ÿæˆç›®çš„ä¸åŒï¼‰
- ç»“æœä¿å­˜åˆ°ï¼š`Results_v2/model_comparison/`

### **åœºæ™¯3ï¼šBaselineå¯¹æ¯”ï¼ˆåŸå§‹æ•°æ® vs åˆæˆæ•°æ®ï¼‰**

```yaml
# training_config.yaml
experiment:
  purpose: "baseline_comparison"  # ğŸ”´ è®­ç»ƒç›®çš„ï¼šå¯¹æ¯”baseline
  description: "å¯¹æ¯”åŸå§‹æ•°æ®å’Œåˆæˆæ•°æ®çš„è®­ç»ƒæ•ˆæœ"

model: "meta-llama/Llama-3.2-1B"
task: "Copa"
method: "zo"

data:
  path: "Data_v2/original/Copa"  # ğŸ”§ ä½¿ç”¨åŸå§‹æ•°æ®ä½œä¸ºbaseline

hyperparameters:
  learning_rate: 5e-7  # ä½¿ç”¨ä¸åˆæˆæ•°æ®ç›¸åŒçš„è¶…å‚æ•°
  batch_size: 16
  steps: 20000
  seed: 0
```

**ç»“æœä¿å­˜åˆ°**ï¼š
```
Results_v2/baseline_comparison/meta-llama/Llama-3.2-1B/Copa_zo_original_5_7/20251226_143000/
```

**å¯¹æ¯”åˆ†æ**ï¼š
```
åˆæˆæ•°æ®ç»“æœï¼šResults_v2/hyperparameter_tuning/.../Copa_zo_copa_mezo_v1_5_7/...
åŸå§‹æ•°æ®ç»“æœï¼šResults_v2/baseline_comparison/.../Copa_zo_original_5_7/...
â†‘ ä¸¤ä¸ªå®éªŒéƒ½ä¿å­˜åœ¨å„è‡ªçš„å®éªŒç›®çš„ç›®å½•ä¸‹ï¼Œæ–¹ä¾¿å¯¹æ¯”
```

---

## ğŸ”§ ç®¡ç†å·¥å…·

### **list_results.py**

åˆ—å‡ºå¹¶ç®¡ç†æ‰€æœ‰è®­ç»ƒç»“æœã€‚

#### **æŸ¥çœ‹æ‘˜è¦**

```bash
python automation/stage2_training/list_results.py
```

**è¾“å‡ºç¤ºä¾‹**ï¼š
```
================================================================================
è®­ç»ƒç»“æœæ‘˜è¦ - Results_v2
================================================================================

ğŸ“ å®éªŒç›®çš„: prompt_engineering
   å®éªŒæ•°é‡: 12
   â””â”€ meta-llama/Llama-3.2-1B: 12 ä¸ªå®éªŒ

ğŸ“ å®éªŒç›®çš„: temperature_study
   å®éªŒæ•°é‡: 8
   â””â”€ meta-llama/Llama-3.2-1B: 8 ä¸ªå®éªŒ

ğŸ“ å®éªŒç›®çš„: baseline
   å®éªŒæ•°é‡: 4
   â””â”€ meta-llama/Llama-3.2-1B: 4 ä¸ªå®éªŒ

================================================================================
æ€»è®¡: 3 ä¸ªå®éªŒç›®çš„, 24 ä¸ªè®­ç»ƒå®éªŒ
================================================================================
```

#### **æŸ¥çœ‹è¯¦ç»†ä¿¡æ¯**

```bash
# æŸ¥çœ‹æ‰€æœ‰å®éªŒçš„è¯¦ç»†ä¿¡æ¯
python automation/stage2_training/list_results.py --detail

# æŸ¥çœ‹ç‰¹å®šå®éªŒç›®çš„çš„è¯¦ç»†ä¿¡æ¯
python automation/stage2_training/list_results.py --detail --purpose prompt_engineering
```

**è¾“å‡ºç¤ºä¾‹**ï¼š
```
================================================================================
è®­ç»ƒç»“æœè¯¦æƒ…
================================================================================

ğŸ“ å®éªŒç›®çš„: prompt_engineering
--------------------------------------------------------------------------------

  [1] Copa_zo_copa_mezo_v1_1_6
      æ¨¡å‹: meta-llama/Llama-3.2-1B
      æ—¶é—´: 20251226_143000
      è·¯å¾„: Results_v2/prompt_engineering/meta-llama/Llama-3.2-1B/Copa_zo_copa_mezo_v1_1_6/20251226_143000
      ä»»åŠ¡: Copa
      æ–¹æ³•: zo
      è¶…å‚æ•°:
        - LR: 1e-06
        - BS: 16
        - Steps: 20000
        - Seed: 0
      æ•°æ®: Data_v2/synthetic/prompt_engineering/copa_mezo_v1/Copa

  [2] Copa_zo_copa_mezo_v1_5_7
      ...
```

---

## ğŸ”„ æ•°æ®-ç»“æœå¯¹åº”å…³ç³»

### **å®Œæ•´çš„å®éªŒè¿½æº¯é“¾**

```
é˜¶æ®µ1ï¼šæ•°æ®ç”Ÿæˆ
Data_v2/synthetic/
â””â”€â”€ prompt_engineering/           # å®éªŒç›®çš„
    â””â”€â”€ copa_mezo_v1/              # å®éªŒID
        â”œâ”€â”€ Copa/                  # æ•°æ®é›†
        â”‚   â”œâ”€â”€ copa_train.jsonl
        â”‚   â”œâ”€â”€ copa_validation.jsonl
        â”‚   â””â”€â”€ copa_test.jsonl
        â””â”€â”€ experiment_metadata.json  # æ•°æ®ç”Ÿæˆå‚æ•°

                    â¬‡

é˜¶æ®µ2ï¼šæ¨¡å‹è®­ç»ƒ
Results_v2/
â””â”€â”€ prompt_engineering/           # ğŸ”— ç›¸åŒçš„å®éªŒç›®çš„
    â””â”€â”€ meta-llama/Llama-3.2-1B/
        â””â”€â”€ Copa_zo_copa_mezo_v1_1_6/
            â””â”€â”€ 20251226_143000/
                â””â”€â”€ experiment_config.yaml  # è®­ç»ƒå‚æ•°
```

### **å¯¹åº”å…³ç³»**

| æ•°æ®é›† | è®­ç»ƒç»“æœ |
|--------|----------|
| `Data_v2/synthetic/{purpose}/{exp_id}/{Dataset}` | `Results_v2/{purpose}/{Model}/{Task}_{Method}_{exp_id}_{LR}/{Timestamp}` |

**å…³é”®ç‚¹**ï¼š
- `{purpose}` åœ¨ä¸¤è¾¹ä¿æŒä¸€è‡´
- `{exp_id}` åœ¨ç»“æœç›®å½•åä¸­ä½“ç°
- é€šè¿‡`experiment_config.yaml`ä¸­çš„`data.path`å¯ä»¥è¿½æº¯åˆ°æºæ•°æ®

---

## ğŸ“Š æœ€ä½³å®è·µ

### **1. è®­ç»ƒå®éªŒç›®çš„å‘½åè§„èŒƒ**

**æ¨èçš„è®­ç»ƒå®éªŒç›®çš„ç±»åˆ«**ï¼ˆé˜¶æ®µ2ï¼‰ï¼š

- `baseline_comparison` - ä¸baselineå¯¹æ¯”
- `model_comparison` - æ¨¡å‹å¯¹æ¯”å®éªŒ
- `hyperparameter_tuning` - è¶…å‚æ•°è°ƒä¼˜
- `ablation_study` - æ¶ˆèå®éªŒ
- `prompt_effectiveness` - æµ‹è¯•promptæ•ˆæœ
- `data_quality_impact` - æµ‹è¯•æ•°æ®è´¨é‡å½±å“
- `scaling_study` - æ‰©å±•æ€§ç ”ç©¶
- `method_comparison` - è®­ç»ƒæ–¹æ³•å¯¹æ¯”ï¼ˆMeZO vs LoRA vs Full FTï¼‰

**æ•°æ®ç”Ÿæˆå®éªŒç›®çš„ç±»åˆ«**ï¼ˆé˜¶æ®µ1ï¼Œä»…ä¾›å‚è€ƒï¼‰ï¼š

- `prompt_engineering` - Promptä¼˜åŒ–å®éªŒ
- `temperature_study` - æ¸©åº¦å‚æ•°ç ”ç©¶
- `data_quality_optimization` - æ•°æ®è´¨é‡ä¼˜åŒ–
- `few_shot_study` - Few-shotç¤ºä¾‹ç ”ç©¶

### **2. é…ç½®æ–‡ä»¶ç»„ç»‡**

æŒ‰**è®­ç»ƒå®éªŒç›®çš„**ç»„ç»‡é…ç½®æ–‡ä»¶ï¼š

```
automation/configs/stage2/
â”œâ”€â”€ baseline_comparison/
â”‚   â”œâ”€â”€ copa_original.yaml
â”‚   â””â”€â”€ boolq_original.yaml
â”œâ”€â”€ model_comparison/
â”‚   â”œâ”€â”€ copa_llama_vs_mistral.yaml
â”‚   â””â”€â”€ copa_llama_1b_vs_3b.yaml
â”œâ”€â”€ hyperparameter_tuning/
â”‚   â”œâ”€â”€ copa_lr_sweep.yaml
â”‚   â””â”€â”€ copa_bs_sweep.yaml
â””â”€â”€ prompt_effectiveness/
    â”œâ”€â”€ copa_v1_vs_v2.yaml
    â””â”€â”€ copa_temp_comparison.yaml
```

**æ³¨æ„**ï¼šé…ç½®æ–‡ä»¶æŒ‰è®­ç»ƒç›®çš„åˆ†ç±»ï¼Œä¸æ˜¯æŒ‰æ•°æ®é›†åˆ†ç±»

### **3. å®éªŒè®°å½•**

æ¯æ¬¡é‡è¦å®éªŒåï¼Œåœ¨å¯¹åº”çš„å®éªŒç›®çš„ç›®å½•ä¸‹è®°å½•ï¼š

```bash
# åœ¨Results_v2/{è®­ç»ƒç›®çš„}/README.mdä¸­è®°å½•
echo "## å®éªŒè®°å½•

### 2025-12-26: å­¦ä¹ ç‡æ‰«æå®éªŒ
- è®­ç»ƒç›®çš„: hyperparameter_tuning
- æ•°æ®é›†: Data_v2/synthetic/prompt_engineering/copa_mezo_v1/
- æ¨¡å‹: Llama-3.2-1B
- å­¦ä¹ ç‡ç½‘æ ¼: [1e-6, 5e-7, 2e-7, 1e-7]
- æœ€ä½³ç»“æœ: LR=5e-7, Acc=85.2%
- å¤‡æ³¨: 5e-7æ˜¯æœ€ä½³å­¦ä¹ ç‡ï¼Œç”¨äºåç»­å®éªŒ
" >> Results_v2/hyperparameter_tuning/README.md
```

---

## âš ï¸ æ³¨æ„äº‹é¡¹

### **1. é˜¶æ®µ1å’Œé˜¶æ®µ2çš„å®éªŒç›®çš„æ˜¯ç‹¬ç«‹çš„ï¼**

ğŸ”´ **æœ€é‡è¦çš„æ¦‚å¿µ**ï¼š

```
âŒ é”™è¯¯ç†è§£ï¼š
   æ•°æ®æ¥è‡ª Data_v2/synthetic/prompt_engineering/...
   â†’ ç»“æœåº”è¯¥ä¿å­˜åˆ° Results_v2/prompt_engineering/

âœ… æ­£ç¡®ç†è§£ï¼š
   æ•°æ®æ¥è‡ª Data_v2/synthetic/prompt_engineering/...  â† æ•°æ®ç”Ÿæˆç›®çš„
   è®­ç»ƒç›®çš„æ˜¯ hyperparameter_tuning                    â† è®­ç»ƒå®éªŒç›®çš„
   â†’ ç»“æœä¿å­˜åˆ° Results_v2/hyperparameter_tuning/
```

### **2. å¿…é¡»æ˜¾å¼æŒ‡å®šè®­ç»ƒå®éªŒç›®çš„**

ç³»ç»Ÿ**ä¸ä¼š**ä»æ•°æ®è·¯å¾„è‡ªåŠ¨æ¨æ–­è®­ç»ƒå®éªŒç›®çš„ï¼š

```yaml
# âŒ é”™è¯¯ï¼šæ²¡æœ‰æŒ‡å®šexperiment.purpose
data:
  path: "Data_v2/synthetic/prompt_engineering/copa_mezo_v1/Copa"
# â†’ ç»“æœä¼šä¿å­˜åˆ° Results_v2/uncategorized/

# âœ… æ­£ç¡®ï¼šæ˜¾å¼æŒ‡å®šè®­ç»ƒç›®çš„
experiment:
  purpose: "hyperparameter_tuning"
data:
  path: "Data_v2/synthetic/prompt_engineering/copa_mezo_v1/Copa"
# â†’ ç»“æœä¿å­˜åˆ° Results_v2/hyperparameter_tuning/
```

### **3. æ—§æ ¼å¼å…¼å®¹æ€§**

ç³»ç»Ÿä»æ”¯æŒæ—§çš„`data.type`æ ¼å¼ï¼Œä½†æ¨èä½¿ç”¨æ–°çš„`data.path`ï¼š

```yaml
# âœ… æ¨èï¼ˆæ–°æ ¼å¼ï¼‰
data:
  path: "Data_v2/synthetic/prompt_engineering/copa_mezo_v1/Copa"

# âš ï¸  å·²å¼ƒç”¨ï¼ˆæ—§æ ¼å¼ï¼‰
data:
  type: "synthetic_mezo_gpt4o_v1"
```

### **3. æ—¶é—´æˆ³éš”ç¦»**

ç›¸åŒé…ç½®çš„å¤šæ¬¡è¿è¡Œä¼šåˆ›å»ºä¸åŒçš„æ—¶é—´æˆ³ç›®å½•ï¼Œé¿å…è¦†ç›–ï¼š

```
Copa_zo_copa_mezo_v1_1_6/
â”œâ”€â”€ 20251226_143000/  # ç¬¬1æ¬¡è¿è¡Œ
â”œâ”€â”€ 20251226_153000/  # ç¬¬2æ¬¡è¿è¡Œ
â””â”€â”€ 20251227_093000/  # ç¬¬3æ¬¡è¿è¡Œ
```

---

## ğŸ‰ æ€»ç»“

### **æ–°ç³»ç»Ÿä¼˜åŠ¿**

1. âœ… **å®éªŒç›®çš„åˆ†ç±»**ï¼šç»“æœæŒ‰å®éªŒç›®çš„è‡ªåŠ¨ç»„ç»‡
2. âœ… **æ™ºèƒ½æ¨æ–­**ï¼šä»æ•°æ®è·¯å¾„è‡ªåŠ¨æ¨æ–­å®éªŒç›®çš„
3. âœ… **å®Œæ•´è¿½æº¯**ï¼šæ•°æ®é›† â†” è®­ç»ƒç»“æœå®Œæ•´å¯¹åº”
4. âœ… **å…ƒæ•°æ®ç®¡ç†**ï¼šè‡ªåŠ¨ä¿å­˜æ‰€æœ‰å®éªŒå‚æ•°
5. âœ… **ç®¡ç†å·¥å…·**ï¼šlist_results.pyå¿«é€ŸæŸ¥çœ‹ç»“æœ

### **ä¸æ—§ç³»ç»Ÿå¯¹æ¯”**

| åŠŸèƒ½ | æ—§ç³»ç»Ÿ | æ–°ç³»ç»Ÿ |
|------|--------|--------|
| ç»“æœç»„ç»‡ | âŒ æ‰€æœ‰ç»“æœæ··åœ¨ä¸€èµ· | âœ… æŒ‰å®éªŒç›®çš„åˆ†ç±» |
| å®éªŒè¿½æº¯ | âŒ æ‰‹åŠ¨è®°å½• | âœ… è‡ªåŠ¨è¿½æº¯åˆ°æ•°æ®é›† |
| é…ç½®ç®¡ç† | âš ï¸  éƒ¨åˆ†ä¿å­˜ | âœ… å®Œæ•´ä¿å­˜ |
| æŸ¥çœ‹å·¥å…· | âŒ æ—  | âœ… list_results.py |

---

**å¼€å§‹æ‚¨çš„è®­ç»ƒå®éªŒï¼** ğŸš€
