# Complete Copa Synthetic Data Generation Configuration Example
# Includes Experiment Management + MeZO Dataset Structure

# ========== Experiment Management (Batch Solution 3++) ==========
experiment:
  # Batch ID - Used to organize multiple experiments into same batch (optional)
  # Format: batch_{date}_{purpose}
  # If not specified, system will auto-generate: batch_{YYYYMMDD}_{purpose}
  batch_id: "batch_20241229_temperature"  # Optional, auto-generated if not filled

  purpose: "prompt_engineering"  # Experiment purpose (used for auto-generating batch_id)
  description: "Copa task prompt optimization experiment"
  experiment_id: "copa_mezo_v1"  # Experiment identifier (deprecated, kept for compatibility)
  overwrite_strategy: "prompt"  # Prompt for overwrite with same parameters (deprecated, Batch solution auto-deduplicates)

# ========== Basic Information ==========
task_name: "Copa"
training_method: "mezo"
version: "v1"

# ========== Dataset Configuration ==========
dataset:
  task_name: "copa"  # Lowercase, used for file naming
  dataset_name: "Copa"  # üîß Uppercase, used for directory naming (expected by MeZO)
  input_path: "Data/original/Copa/copa_train.jsonl"

  # üîß Original dataset directory (for copying validation/test)
  original_dir: "Data/original/Copa"

  # üîß Dataset file list
  files:
    train: "copa_train.jsonl"
    validation: "copa_validation.jsonl"
    test: "copa_test.jsonl"

  fields:
    - "premise"
    - "choice1"
    - "choice2"
    - "question"
    - "label"

# ========== Generation configuration ==========
generation:
  # ‚≠ê Rewriter API Configuration
  api_key: "sk-eWSYPo0CvhRYgcJs55B0C3F00aC74f6e95F47c1f4772292c"
  base_url: "https://api2.aigcbest.top/v1"
  timeout: 120

  model: "gpt-4o"
  temperature: 0.9
  field_to_rephrase: "premise"  # ‚≠ê Specify field to rephrase

  # ‚≠ê Rephrase Prompt - Supports placeholders and field references
  # - {{REPHRASE_FEWSHOT}}: System will auto-insert few-shot examples (from checkpoint 1 approved samples)
  # - {field_name}: Use Python .format() syntax to reference field values
  rephrase_prompt: |
    You are tasked with rephrasing the given premise while preserving its original meaning. Your goal is to create rephrased data optimized for enhancing gradient estimation in training with a memory-efficient zeroth-order optimizer (MeZO).

    {{REPHRASE_FEWSHOT}}

    ### Key Requirements for Premise Rephrasing:
    1. **Task-Specific Context**:
       - The **Copa dataset** focuses on **causal reasoning**, where the goal is to determine the **cause or effect** of a given premise.
       - The rephrased **premise** must **not alter the logical relationship** with the correct choice.

    2. **Consistency with Correct Answer**:
       - Ensure that the rephrased premise maintains the same correct answer as the original.
       - The correct answer is: Choice {label + 1}: "{choice1 if label == 0 else choice2}"

    3. **Optimized for MeZO Training**:
       - **Enhance Gradient Sensitivity**: Create clear semantic boundaries to increase gradient sensitivity.
       - **Focus on Memory Efficiency**: Reduce redundancy, keep sentences concise.
       - **Robustness to Data Sparsity**: Ensure essential information is preserved.
       - **Non-Differentiable Optimization Readiness**: Create clear impacts on performance metrics.

    4. **Maintain Neutral Stance**:
       - Do not explicitly indicate which choice is correct.
       - The rephrased premise should require reasoning to determine the answer.

    5. **High-Quality Data Generation**:
       - Produce natural, fluent, and coherent text.
       - Use paraphrasing, synonyms, or restructuring to diversify data.

    ### Your Task:
    Rephrase the following premise while ensuring it remains consistent with the correct answer.

    **Original premise**: "{premise}"
    **Choice 1**: "{choice1}"
    **Choice 2**: "{choice2}"
    **Question**: "{question}"
    **Correct answer**: "{choice1 if label == 0 else choice2}"

    **Directly output only one rephrased premise** without any other characters or explanatory statements:

# ========== Validation configuration ==========
validation:
  # ‚≠ê Judge API Configuration
  api_key: "sk-eWSYPo0CvhRYgcJs55B0C3F00aC74f6e95F47c1f4772292c"
  base_url: "https://api2.aigcbest.top/v1"
  timeout: 120

  model: "gpt-4o"
  temperature: 0.0

  # ‚≠ê Validation Prompt - Supports placeholders and field references
  # - {{VALIDATION_FEWSHOT}}: System will auto-insert few-shot examples (from checkpoint 2A approved samples 21-40)
  # - {original_field}, {rephrased_field}: Use Python .format() syntax to reference field values
  validation_prompt: |
    Task: Verify if the rephrased premise maintains consistency with the correct answer choice.

    {{VALIDATION_FEWSHOT}}

    Original premise: "{original_premise}"
    Rephrased premise: "{rephrased_premise}"
    Choice 1: "{original_choice1}"
    Choice 2: "{original_choice2}"
    Question: "{original_question}"
    Correct answer: "{original_choice1 if original_label == 0 else original_choice2}"

    Output [same/not the same]:

  # ‚≠ê Few-shot examples - Can be left empty initially, system will auto-generate after checkpoint 2A
  few_shot_examples:
    - original_premise: "My body cast a shadow over the grass."
      rephrased_premise: "A shadow from my body fell across the grass."
      choice1: "The sun was rising."
      choice2: "The grass was cut."
      question: "cause"
      label: 0
      evaluation: "same"

    - original_premise: "The woman tolerated her friend's difficult behavior."
      rephrased_premise: "The woman accepted her friend's challenging conduct."
      choice1: "The woman knew her friend was going through a hard time."
      choice2: "The woman felt that her friend took advantage of her kindness."
      question: "cause"
      label: 0
      evaluation: "same"

    - original_premise: "The women met for coffee."
      rephrased_premise: "The two women decided to gather at a caf√©."
      choice1: "The cafe reopened in a new location."
      choice2: "They wanted to catch up with each other."
      question: "cause"
      label: 1
      evaluation: "same"
