# è®­ç»ƒPipelineé…ç½®æ–‡ä»¶ç¤ºä¾‹

# ========== å®éªŒç®¡ç† ==========
experiment:
  # ğŸ”´ é‡è¦ï¼šè¿™æ˜¯"è®­ç»ƒ"çš„å®éªŒç›®çš„ï¼Œä¸"æ•°æ®ç”Ÿæˆ"çš„å®éªŒç›®çš„ç‹¬ç«‹ï¼
  # è®­ç»ƒå®éªŒç›®çš„ç¤ºä¾‹ï¼š
  #   - model_comparison: å¯¹æ¯”ä¸åŒæ¨¡å‹æ•ˆæœ
  #   - hyperparameter_tuning: è°ƒæ•´è¶…å‚æ•°
  #   - baseline_comparison: ä¸baselineå¯¹æ¯”
  #   - ablation_study: æ¶ˆèå®éªŒ
  #   - prompt_effectiveness: æµ‹è¯•promptæ•ˆæœ
  purpose: "model_comparison"  # è®­ç»ƒå®éªŒç›®çš„ï¼ˆResultsåˆ†ç±»ä¾æ®ï¼‰
  description: "å¯¹æ¯”ä¸åŒæ¨¡å‹åœ¨Copaåˆæˆæ•°æ®ä¸Šçš„è¡¨ç°"

# æ¨¡å‹é…ç½®
model: "meta-llama/Llama-3.2-1B"  # æˆ– "mistralai/Mistral-Nemo-Base-2407"

# ä»»åŠ¡
task: "Copa"  # Copa, CB, RTE, BOOLQ, ArcC_Cloze, ArcC_MC

# è®­ç»ƒæ–¹æ³•
method: "zo"  # zo (MeZO), fo_full (Full Fine-tune), fo_lora (LoRA)

# æ•°æ®é…ç½®
data:
  # ğŸ†• æ¨èæ ¼å¼ï¼šç›´æ¥æŒ‡å®šæ•°æ®è·¯å¾„ï¼ˆä¼šè‡ªåŠ¨æ¨æ–­experiment_purposeï¼‰
  path: "Data_v2/synthetic/prompt_engineering/copa_mezo_v1/Copa"

  # æ—§æ ¼å¼ï¼ˆå·²å¼ƒç”¨ä½†ä»æ”¯æŒï¼‰ï¼š
  # type: "original"  # æ•°æ®ç±»å‹
  #   - "original": åŸå§‹æ•°æ®
  #   - "synthetic_{method}_{model}_{version}": åˆæˆæ•°æ®
  #   - "mixed_{method}_{model}_{version}": æ··åˆæ•°æ®

# è¶…å‚æ•°é…ç½® (æ”¯æŒå•å€¼æˆ–åˆ—è¡¨è¿›è¡Œç½‘æ ¼æœç´¢)
hyperparameters:
  learning_rate:  # å­¦ä¹ ç‡ (å¯ä»¥æ˜¯å•å€¼æˆ–åˆ—è¡¨)
    - 1e-6
    - 5e-7
    - 2e-7
    - 1e-7

  batch_size: 16  # Batch size

  steps: 20000  # è®­ç»ƒæ­¥æ•°

  seed: 0  # éšæœºç§å­ (å¯ä»¥æ˜¯å•å€¼æˆ–åˆ—è¡¨)

  # MeZO ç‰¹å®šå‚æ•°
  zo_eps: 1e-3  # MeZO çš„ epsilon å‚æ•°

  # LoRA ç‰¹å®šå‚æ•° (ä»…åœ¨ method=fo_lora æ—¶ä½¿ç”¨)
  lora_rank: 8
  lora_alpha: 16

# CUDAè®¾å¤‡é…ç½®
cuda_devices: "0"  # å¯ä»¥æ˜¯ "0", "0,1", "0,1,2,3" ç­‰

# è¿è¡Œé€‰é¡¹
wait_for_completion: false  # æ˜¯å¦ç­‰å¾…è®­ç»ƒå®Œæˆ (falseåˆ™åå°è¿è¡Œ)
continue_on_error: true  # å‡ºé”™æ—¶æ˜¯å¦ç»§ç»­æ‰§è¡Œå‰©ä½™å®éªŒ
