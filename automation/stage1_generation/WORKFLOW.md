# Stage 1CompleteWorkflowprocessï¼šManual checkpoint + Parameter tuningRepeat use 

versionDocumentDescriptionNewAutomated System such as whatsupportï¼š
1. **First timeGenerate**ï¼šcontain3must need Manual checkpointValidate
2. **Parameter tuningExperiment**ï¼šbase at alreadyValidatepromptï¼ŒQuick parameter tuningRepeat use 

---

## âœ… ImplementationStatus

### ImplementedTool

| Tool | location | Feature | Status |
|------|------|------|------|
| `generator.py` | `automation/stage1_generation/` | Generaterephrase and validationScript | âœ… **alreadyFix** |
| `review_top20.py` | `automation/stage1_generation/tools/` | Checkpoint1ï¼šmanual review front 20Sample | âœ… Implemented |
| `extract_samples.py` | `automation/stage1_generation/tools/` | ExtractSpecifyScopeSample | âœ… Implemented |
| `annotate_samples.py` | `automation/stage1_generation/tools/` | Checkpoint2ï¼šManual annotation21-80Sample | âœ… Implemented |
| `generate_validation_test.py` | `automation/stage1_generation/tools/` | GeneratejudgerTestScript | âœ… Implemented |

### ğŸ”§ Key fixes

**generator.py (validate.pyGenerateLogic)**:
- âœ… **alreadyFixExclude21-40SampleLogic**
- Generate`validate.py`current in  will skipSample21-40ï¼ˆIndex20-39ï¼‰
- theseSample use asjudgerfew-shot examplesï¼ŒShould not by judgerValidateï¼ˆAvoidDataLeakï¼‰
- Fixlocationï¼š`generator.py:300-308`

```python
# ğŸ”´ ExcludeSample21-40ï¼ˆIndex20-39ï¼‰
if 20 <= i < 40:
    # DirectlyuseSyntheticDataï¼ŒWithoutjudgerValidate
    out_file.write(json.dumps(synthetic, ensure_ascii=False) + "\n")
    correct_count += 1
    total_count += 1
    continue
```

---

## âš ï¸ ImportantDescription

### OnlySynthetictrainData

**PipelineOnly will Synthetic/RephrasetrainingDataï¼ˆtrain.jsonlï¼‰ï¼Œvalidation and testDataDirectly from originalDataCollectCopy**ï¼š

- âœ… **{dataset}_train.jsonl** â†’ SyntheticDataï¼ˆalreadyrephrase + validation + rejection samplingï¼‰
- ğŸ“‹ **{dataset}_validation.jsonl** â†’ originalDataï¼ˆ from  Data/original/ Copyï¼‰
- ğŸ“‹ **{dataset}_test.jsonl** â†’ originalDataï¼ˆ from  Data/original/ Copyï¼‰

 this Do thisYes as ï¼š
1. **Maintainevaluationstandardation** - validation and testDataMaintainoriginalStatusï¼ŒEnsureFairEvaluate
2. **Experiment Results can compare** - DifferentExperimentusesameevaluationData
3. **SymbolResearch conventions** - Only in trainingstageuseSyntheticDataenhance

**Automaticprocess**: `validate.py`  in ValidatetrainData back ï¼Œ will Automatic from originalDataCollectCopyvalidation and testFileã€‚

---

## ğŸ—‚ï¸ BatchSolution3++ - smart can ExperimentManage

### whatYesBatchSolutionï¼Ÿ

BatchSolution3++pass**Physicalstorage and LogicviewGraphSeparation**ï¼ŒImplementationMoreParameterExperimentsmart can Manage and AutomaticremoveHeavyã€‚

**coreMechanism**:
- **Physicalstorage (_shared/)**: StoreActualDataï¼Œ according to ParameterFingerprintremoveHeavy
- **LogicviewGraph (batch_*)**: passSymbolIDLinkOrganizeExperimentï¼Œ according to time/objectiveGroup

**ParameterremoveHeavy**: sameParameter configurationDataOnlyGenerateOnceï¼ŒDifferentbatchcanRepeat use 

### DirectorystructureExample

```
Data_v2/synthetic/
â”œâ”€â”€ _shared/                                    # PhysicalDataï¼ˆremoveHeavyï¼‰
â”‚   â””â”€â”€ Copa/
â”‚       â”œâ”€â”€ temp05_topp10_gpt4o/               # ActualData
â”‚       â”œâ”€â”€ temp07_topp09_gpt4o/
â”‚       â””â”€â”€ temp09_topp10_gpt4o/
â”‚
â”œâ”€â”€ batch_20241229_temperature/                 # Batch 1: TemperatureExperiment
â”‚   â””â”€â”€ Copa/
â”‚       â”œâ”€â”€ temp05_topp10_gpt4o -> ../../_shared/...
â”‚       â”œâ”€â”€ temp07_topp10_gpt4o -> ../../_shared/...
â”‚       â””â”€â”€ temp09_topp10_gpt4o -> ../../_shared/...
â”‚
â””â”€â”€ batch_20241230_topp/                        # Batch 2: top_pExperiment
    â””â”€â”€ Copa/
        â”œâ”€â”€ temp07_topp08_gpt4o -> ../../_shared/...
        â””â”€â”€ temp07_topp09_gpt4o -> ../../_shared/...  # Repeat use ï¼
```

### ConfigurationFileSettings

 in ConfigurationFile in add `experiment.batch_id`:

```yaml
experiment:
  # Batch IDï¼ˆ can selectï¼ŒnotSpecifythenAutomaticGenerateï¼‰
  batch_id: "batch_20241229_temperature"
  purpose: "temperature_study"
  description: "ResearchtemperatureParameter for SyntheticDataqualityImpact"

generation:
  model: "gpt-4o"
  temperature: 0.7  # Experimentvariable
  # ...
```

### AutomaticremoveHeavyOriginalmanage

When youRun `generator.py` Sometimesï¼š

1. **CalculateParameterFingerprint**: base at allImpactDataGenerateParameterï¼ˆModelã€temperatureã€top_pã€prompts etc.ï¼‰
2. **FindalreadyhasData**:  in  `_shared/{Dataset}/`  in SearchsameFingerprint
3. **Repeat use  or New**:
   - find to sameFingerprint â†’ Repeat use PhysicalDataï¼ŒCreatebatchSymbolIDLink
   - Not found to  â†’ CreateNewPhysicalDirectoryï¼ŒGenerateData

**Sectionsaveresource**: NoneneedRepeatGeneratesameParameterDataï¼ŒSectionsaveAPIadjust use Cost and time

### BatchManageTool

```bash
# Columnoutallbatch
python automation/stage1_generation/batch_tools/list_batches.py --verbose

# ViewbatchDetails
python automation/stage1_generation/batch_tools/list_batch_experiments.py \
    batch_20241229_temperature --verbose

# ViewPhysicalDatauseCase
python automation/stage1_generation/batch_tools/list_shared_experiments.py \
    --dataset Copa --verbose

# compareExperimentParameter
python automation/stage1_generation/batch_tools/compare_experiments.py \
    --shared Copa/temp07_topp10_gpt4o \
    --shared Copa/temp09_topp10_gpt4o
```

**DetailedDescription**: See [BATCH_GUIDE.md](../../BATCH_GUIDE.md)

---

## WorkflowProcess overview

```
First timeGenerateï¼ˆhasManual checkpointï¼‰              Parameter tuningExperimentï¼ˆNoneManual checkpointï¼‰
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. CreatedraftConfiguration        â”‚          â”‚ 1. base at validatedTemplate    â”‚
â”‚    (ManualWriteinitialprompt) â”‚          â”‚    CreateExperimentConfiguration         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚                                   â”‚
            v                                   v
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. GenerateScript             â”‚          â”‚ 2. GenerateScript             â”‚
â”‚    (generator.py)      â”‚          â”‚    (generator.py)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚                                   â”‚
            v                                   v
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ğŸ”´ Checkpoint1: Reviewtop20    â”‚          â”‚ 3. DirectlyRun             â”‚
â”‚    â†’ Generatefew-shot      â”‚          â”‚    rephrase_all.py     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚    (Noneneedmanual review)      â”‚
            â”‚                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            v                                   â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                     â”‚
â”‚ 3. GeneraterestData         â”‚                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚
            â”‚                                   â”‚
            v                                   â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                     â”‚
â”‚ ğŸ”´ Checkpoint2: Annotate21-80    â”‚                     â”‚
â”‚    â†’ Generatevalidation    â”‚                     â”‚
â”‚       prompt few-shot  â”‚                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚
            â”‚                                   â”‚
            v                                   v
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ğŸ”´ Checkpoint3: Testprompt   â”‚          â”‚ 4. usealreadyValidate         â”‚
â”‚    â†’ Tunedirect to â‰¥95%      â”‚          â”‚    validation prompt   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚    ValidateData             â”‚
            â”‚                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            v                                   â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                     â”‚
â”‚ 4. batchValidateData         â”‚                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚
            â”‚                                   â”‚
            v                                   v
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 5. Archive as validatedTemplate  â”‚          â”‚ 5. Completeï¼               â”‚
â”‚    ( can Repeat use )            â”‚          â”‚    comparisonDifferentVersionquality     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ScenarioAï¼šFirst timeGenerateï¼ˆneedManualValidateï¼‰

###  front setCondition
- originalDataalreadyAccurateprepareï¼š`Data/original/{Task}/{task}_train.jsonl`
- You haveManualWriteinitialversionpromptï¼ˆNonefew-shotï¼‰

### Step 1: CreatedraftConfiguration

CreateConfigurationFileï¼š`automation/configs/stage1/drafts/copa_mezo_v1_draft.yaml`

```yaml
task_name: "Copa"
training_method: "mezo"
version: "v1"

dataset:
  task_name: "copa"
  input_path: "Data/original/Copa/copa_train.jsonl"
  fields: ["premise", "choice1", "choice2", "question", "label"]

generation:
  model: "gpt-4o"
  temperature: 0.5
  field_to_rephrase: "premise"

  # ManualWriteinitialpromptï¼ˆNonefew-shotï¼‰
  rephrase_prompt: |
    You are tasked with rephrasing...
    ï¼ˆManualWritepromptContentï¼‰

validation:
  model: "gpt-4o"
  temperature: 0.0

  # ManualWriteinitialvalidation promptï¼ˆNonefew-shotï¼‰
  validation_prompt: |
    Judge if the rephrased premise...
    ï¼ˆManualWritepromptContentï¼‰

  # tempSometimeskeepNullï¼Œ back continueAutomaticGenerate
  few_shot_examples: []
```

### Step 2: GenerateScript

```bash
python automation/stage1_generation/generator.py \
       automation/configs/stage1/drafts/copa_mezo_v1_draft.yaml
```

**output**ï¼š
```
Data_v2/synthetic/Copa_mezo_gpt4o_v1/
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ rephrase_top20.py
â”‚   â”œâ”€â”€ rephrase_rest.py
â”‚   â”œâ”€â”€ rephrase_all.py
â”‚   â””â”€â”€ validate.py
â”œâ”€â”€ generation_config.yaml
â””â”€â”€ README.md
```

### Step 3: Generate front 20Sample

```bash
cd Data_v2/synthetic/Copa_mezo_gpt4o_v1/scripts/
export OPENAI_API_KEY="your-key"
python rephrase_top20.py
```

**output**ï¼š`copa_train_top20.jsonl`ï¼ˆ20Sampleï¼‰

---

### ğŸ”´ **Checkpoint1ï¼šmanual reviewtop20Sample**

#### 3.1 Side by sideVieworiginalvsSyntheticData

```bash
# usemanual reviewToolï¼ˆTo be implementedï¼‰
python review_top20.py
```

**ReviewInterfaceExample**ï¼š
```
Sample 1/20:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
originalpremise:
  "My body cast a shadow over the grass."

Syntheticpremise:
  "A shadow from my body fell across the grass."

Choice 1: The sun was rising.
Choice 2: The grass was cut.
Question: cause
Correct answer: Choice 1

This rephraseYesNoqualifiedï¼Ÿ
  [y] qualified - SemanticsConsistentï¼ŒqualityGood
  [n] unqualified - SemanticsChange or qualitydifference
  [s] skip
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
youJudgment: y

ï¼ˆContinueReviewSample2-20...ï¼‰
```

**output**ï¼š
```json
// validation_checkpoints/top20_review.json
{
  "total": 20,
  "approved": 18,
  "rejected": 2,
  "annotations": [
    {
      "index": 0,
      "original": "My body cast a shadow over the grass.",
      "rephrased": "A shadow from my body fell across the grass.",
      "judgment": "approved",
      "note": ""
    },
    // ... 19MoreSample
  ]
}
```

#### 3.2 AutomaticGeneratefew-shotAnd inject to rephrase_rest.py

```bash
# base at ReviewresultAutomaticGeneratefew-shot examples
python update_rest_prompt.py
```

**Feature**ï¼š
1. read`top20_review.json`
2. Extract`judgment == "approved"`Sample
3. formatIntofew-shot examples
4. AutomaticUpdate`rephrase_rest.py` in prompt

---

### Step 4: GenerateRemaining380Sample

```bash
python rephrase_rest.py
# current in prompt in containmanual reviewpassfew-shot examples
```

**output**ï¼š`copa_train_rest.jsonl`ï¼ˆ380Sampleï¼‰

### Step 5: MergeData

```bash
cat copa_train_top20.jsonl copa_train_rest.jsonl > ../copa_train.jsonl
```

---

### ğŸ”´ **Checkpoint2ï¼šManual annotationline21-80Sample**

> **âœ… ToolImplemented**: `extract_samples.py`, `annotate_samples.py` Bit at  `automation/stage1_generation/tools/`

#### 5.1 Extractline21-80Sample

```bash
# EnterDataCollectDirectory
cd Data_v2/synthetic/{experiment_purpose}/{experiment_id}/{Dataset}/

# ExtractSample21-80ï¼ˆTotal60ï¼‰
python /path/to/automation/stage1_generation/tools/extract_samples.py \
    --range 21-80 \
    --input Copa/copa_train.jsonl

#  or er in toolsDirectoryDirectlyRun
cd /path/to/automation/stage1_generation/tools/
python extract_samples.py \
    --range 21-80 \
    --input /path/to/Copa/copa_train.jsonl
```

**output**ï¼š
```
validation_checkpoints/samples_21_80.jsonl  # 60Sample
```

#### 5.2 Manual annotation

```bash
#  in DataCollectDirectory or toolsDirectoryRun
python annotate_samples.py validation_checkpoints/samples_21_80.jsonl

#  can selectParameterï¼š
# --output validation_checkpoints/custom_name_annotated.json  # CustomoutputFile
# --no-resume                                                  # HeavyNewOnstartï¼ŒnotContinue up timesAnnotate
```

**AnnotateInterfaceExample**ï¼š
```
Sample 1/60 (originalDataline21):
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
originalpremise:
  "The tenant misplaced his keys."

Syntheticpremise:
  "The tenant lost his apartment keys."

Choice 1: His landlord unlocked the door.
Choice 2: His landlord repaired the door.
Question: effect
Correct answer: Choice 1

SemanticsYesNoConsistentï¼Ÿ
  [s] same - SemanticsConsistent
  [n] not the same - SemanticsChange
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
youJudgment: s

ï¼ˆContinueAnnotateSample2-60...ï¼‰
```

**output**ï¼š
```json
// validation_checkpoints/samples_21_80_annotated.json
{
  "total": 60,
  "same": 57,
  "not_the_same": 3,
  "annotations": [
    {
      "index": 20,  // originalData in Indexï¼ˆline21ï¼‰
      "original_premise": "The tenant misplaced his keys.",
      "rephrased_premise": "The tenant lost his apartment keys.",
      "choice1": "His landlord unlocked the door.",
      "choice2": "His landlord repaired the door.",
      "question_type": "effect",
      "correct_answer": "Choice 1",
      "judgment": "same",  // ManualJudgment
      "note": ""
    },
    // ... 59MoreSample
  ]
}
```

#### 5.3 AutomaticGeneratevalidation promptTestScript

> **âœ… ToolImplemented**: `generate_validation_test.py` Bit at  `automation/stage1_generation/tools/`

```bash
# useDefaultPath
python /path/to/automation/stage1_generation/tools/generate_validation_test.py

#  or SpecifyParameter
python generate_validation_test.py \
    --annotations validation_checkpoints/samples_21_80_annotated.json \
    --fewshot-range 21-40 \
    --test-range 41-80 \
    --output scripts/validate_prompt_test.py \
    --api-key your-api-key \
    --base-url https://api.openai.com/v1
```

**Feature**ï¼š
1. read`samples_21_80_annotated.json`
2. **line21-40"same"Sample** â†’ formatIntovalidation promptfew-shot examples
3. **line41-80allSample** â†’ formatIntotest_setï¼ˆcontainground truthï¼‰
4. AutomaticGenerate`validate_prompt_test.py`

**GenerateTestScript**ï¼š
```python
# scripts/validate_prompt_test.py
def generate_validation_prompt(...):
    return f"""
    Judge if the rephrased premise...

    ### Few-shot Examples (Fromline21-40):
    Example 1:
    Original: The tenant misplaced his keys.
    Rephrased: The tenant lost his apartment keys.
    Judgment: same

    ... (Total20few-shot)
    """

# Test setï¼ˆFromline41-80ï¼ŒTotal40ï¼‰
test_set = [
    {
        "original_premise": "...",
        "rephrased_premise": "...",
        "ground_truth": "same"  # Manual annotation
    },
    ...
]

# Testpromptaccuracy
for item in test_set:
    response = gpt4o_judge(item)
    if response == item["ground_truth"]:
        correct += 1

accuracy = correct / len(test_set)
print(f"Promptaccuracy: {accuracy:.2%}")
```

---

### ğŸ”´ **Checkpoint3ï¼šTestandTunevalidation prompt**

#### 6.1 Testpromptaccuracy

```bash
python validate_prompt_test.py
```

**outputExample**ï¼š
```
Testing validation prompt on 40 samples...
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Test Results:
  Correct: 36 / 40
  Accuracy: 90.0%

âœ— PromptNot met standardï¼ˆneedâ‰¥95%ï¼‰

ErrorSample:
  Sample 23: Judgment as sameï¼ŒActual as not the same
  Sample 45: Judgment as not the sameï¼ŒActual as same
  Sample 67: Judgment as sameï¼ŒActual as not the same
  Sample 78: Judgment as not the sameï¼ŒActual as same

Recommendation:
  1. Checkfew-shot examples in YesNocontainclassSimilar counter examples
  2. adjustmentvalidation_prompt in JudgmentstandardDescribe
  3. Increase for BoundaryCaseDescription

pleaseManualadjustmentConfigurationFile in validation_promptï¼Œnatural back HeavyNewRunthisTestã€‚
```

#### 6.2 ManualTuneprompt

EditConfigurationFileï¼š
```bash
vim automation/configs/stage1/drafts/copa_mezo_v1_draft.yaml
```

Modify`validation.validation_prompt`ï¼Œexample such as ï¼š
- addMoreExplicitJudgmentstandard
- SupplementBoundaryCasefew-shot examples
- adjustmentprompt use Word

#### 6.3 HeavyNewGenerateScriptandTest

```bash
# HeavyNewGenerateScript
python automation/stage1_generation/generator.py \
       automation/configs/stage1/drafts/copa_mezo_v1_draft.yaml

# HeavyNewTest
cd Data_v2/synthetic/Copa_mezo_gpt4o_v1/scripts/
python validate_prompt_test.py
```

**Repeat6.1-6.3direct to accuracyâ‰¥95%**ï¼š
```
Test Results:
  Correct: 39 / 40
  Accuracy: 97.5%

âœ“ PromptMet the standardï¼
  CreatepassTag: validation_checkpoints/prompt_test_passed.flag
```

---

### Step 7: batchValidateall400Sample

```bash
python validate.py
```

**Feature**ï¼š
1. CheckYesNoexist in `prompt_test_passed.flag`ï¼ˆGateï¼‰
2.  such as If does not exist in ï¼ŒRejectExecuteandTipfirstRunTest
3.  such as If exists in ï¼ŒusealreadyValidatevalidation promptValidateall400Sample
4. Rejection samplingï¼šunqualified use originalDataReplace

**output**ï¼š
```
ValidateComplete!
Pass rate: 381/400 = 95.25%
outputFile: copa_train_validated.jsonl
```

---

### Step 8: Archive as validatedTemplate

```bash
cd /home/ubuntu/LLM-inference/jikai-project/Synthetic_Data_for_ZO/

python automation/stage1_generation/archive_validated_config.py \
       --source automation/configs/stage1/drafts/copa_mezo_v1_draft.yaml \
       --data-dir Data_v2/synthetic/Copa_mezo_gpt4o_v1/
```

**output**ï¼š
```
âœ“ ConfigurationalreadyArchive!

TemplatePath: automation/configs/stage1/templates/copa_mezo_validated.yaml
ArchivePath: automation/configs/stage1/archive/2024-12/copa_mezo_v1_complete_20241224_153000.yaml

current in canbase at thisTemplateCreateParameter tuningExperimentConfigurationã€‚
```

---

## ScenarioBï¼šParameter tuningExperimentï¼ˆbase at alreadyValidatepromptï¼‰

###  front setCondition
- alreadyhasvalidatedTemplateï¼š`automation/configs/stage1/templates/copa_mezo_validated.yaml`
- PromptPassedallManualValidate
- want need adjustmentGenerateParameterObserve for DataqualityImpact

### Step 1: CreateExperimentConfiguration

```bash
# Experiment1: Raisetemperature
python automation/stage1_generation/create_experiment.py \
       --template automation/configs/stage1/templates/copa_mezo_validated.yaml \
       --version v2 \
       --param generation.temperature=0.7
```

**output**ï¼š
```
âœ“ ConfigurationalreadyCreate: automation/configs/stage1/experiments/copa_mezo_v2_temperature07.yaml

ParameterchangeMore:
  - generation.temperature: 0.5 â†’ 0.7
```

### Step 2: GenerateScript

```bash
python automation/stage1_generation/generator.py \
       automation/configs/stage1/experiments/copa_mezo_v2_temperature07.yaml
```

**output**ï¼š
```
Data_v2/synthetic/Copa_mezo_gpt4o_v2/
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ rephrase_all.py      # containalreadyValidatefew-shot
â”‚   â”œâ”€â”€ rephrase_top20.py
â”‚   â”œâ”€â”€ rephrase_rest.py
â”‚   â””â”€â”€ validate.py          # containalreadyValidatevalidation prompt
â””â”€â”€ ...
```

### Step 3: DirectlyGenerateCompleteDataCollectï¼ˆNoneneedmanual reviewï¼‰

```bash
cd Data_v2/synthetic/Copa_mezo_gpt4o_v2/scripts/
export OPENAI_API_KEY="your-key"

# DirectlyRunrephrase_all.pyï¼ˆ400Sampleï¼‰
python rephrase_all.py
```

**Key**ï¼š
- âœ… usealreadyValidatefew-shot examples
- âœ… OnlyhastemperatureChangeï¼ˆ0.5 â†’ 0.7ï¼‰
- âœ… NoneneedRepeatmanual reviewCheckpoint1-3

### Step 4: usealreadyValidatevalidation promptValidate

```bash
python validate.py
```

**output**ï¼š
```
ValidateComplete!
Pass rate: 378/400 = 94.5%
outputFile: copa_train_validated.jsonl
```

### Step 5: comparisonDifferentVersion

```bash
# comparisonv1 and v2Dataquality
python automation/analysis/compare_versions.py \
       --v1 Data_v2/synthetic/Copa_mezo_gpt4o_v1/copa_train_validated.jsonl \
       --v2 Data_v2/synthetic/Copa_mezo_gpt4o_v2/copa_train_validated.jsonl
```

**output**ï¼š
```
Versioncomparison:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
metrics                   v1          v2
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ValidatePass rate           95.25%      94.50%
averageEditDistance         12.3        15.7
WordGatherMoreDiversity (TTR)     0.82        0.87
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Conclusion: v2 (temp=0.7) MoreDiversityHigherï¼ŒButPass rateSlightlyLow
```

---

## MoreExperimentparallel

```bash
# CreatemultipleExperimentConfiguration
python automation/stage1_generation/create_experiment.py \
       --template automation/configs/stage1/templates/copa_mezo_validated.yaml \
       --version v3 \
       --param generation.model=gpt-4o-mini

python automation/stage1_generation/create_experiment.py \
       --template automation/configs/stage1/templates/copa_mezo_validated.yaml \
       --version v4 \
       --param generation.temperature=0.9

# parallelGenerateï¼ˆuseDifferentGPU or timeParagraphï¼‰
for version in v2 v3 v4; do
  config="automation/configs/stage1/experiments/copa_mezo_${version}_*.yaml"
  python automation/stage1_generation/generator.py $config
  cd Data_v2/synthetic/Copa_mezo_*_${version}/scripts/
  python rephrase_all.py &
  cd -
done
```

---

## DirectorystructureSummary

```
automation/configs/stage1/
â”œâ”€â”€ drafts/                                    # First timeGenerateï¼špendingValidateConfiguration
â”‚   â””â”€â”€ copa_mezo_v1_draft.yaml               # ManualWriteinitialprompt
â”‚
â”œâ”€â”€ templates/                                 # alreadyValidateTemplateï¼ˆ can Repeat use ï¼‰
â”‚   â”œâ”€â”€ copa_mezo_validated.yaml              # CopataskMeZOmethodTemplate
â”‚   â”œâ”€â”€ rte_mezo_validated.yaml               # RTEtaskTemplate
â”‚   â””â”€â”€ README.md
â”‚
â”œâ”€â”€ experiments/                               # Parameter tuningExperimentConfiguration
â”‚   â”œâ”€â”€ copa_mezo_v2_temperature07.yaml       # Experimentï¼štemp=0.7
â”‚   â”œâ”€â”€ copa_mezo_v3_gpt4omini.yaml           # Experimentï¼šchangeModel
â”‚   â””â”€â”€ copa_mezo_v4_temperature09.yaml       # Experimentï¼štemp=0.9
â”‚
â”œâ”€â”€ archive/                                   # HistoryArchive
â”‚   â””â”€â”€ 2024-12/
â”‚       â””â”€â”€ copa_mezo_v1_complete_20241224.yaml
â”‚
â””â”€â”€ examples/                                  # Example
    â””â”€â”€ stage1_example_copa_mezo.yaml

Data_v2/synthetic/Copa_mezo_gpt4o_v1/
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ rephrase_top20.py
â”‚   â”œâ”€â”€ rephrase_rest.py
â”‚   â”œâ”€â”€ rephrase_all.py
â”‚   â”œâ”€â”€ validate.py
â”‚   â”œâ”€â”€ review_top20.py                       # ğŸ†• manual reviewTool
â”‚   â”œâ”€â”€ annotate_samples.py                   # ğŸ†• Manual annotationTool
â”‚   â”œâ”€â”€ validate_prompt_test.py               # ğŸ†• AutomaticGenerateTestScript
â”‚   â”œâ”€â”€ extract_samples.py                    # ğŸ†• SampleExtract
â”‚   â”œâ”€â”€ update_rest_prompt.py                 # ğŸ†• AutomaticInjectfew-shot
â”‚   â””â”€â”€ generate_validation_test.py           # ğŸ†• GenerateTestScript
â”œâ”€â”€ validation_checkpoints/                    # ğŸ†• ManualValidateRecord
â”‚   â”œâ”€â”€ top20_review.json                     # Checkpoint1Record
â”‚   â”œâ”€â”€ samples_21_80_annotated.json          # Checkpoint2Record
â”‚   â”œâ”€â”€ prompt_test_results.json              # Checkpoint3Record
â”‚   â””â”€â”€ prompt_test_passed.flag               # passTag
â”œâ”€â”€ copa_train_top20.jsonl
â”œâ”€â”€ copa_train_rest.jsonl
â”œâ”€â”€ copa_train.jsonl                          # Merge back notValidateData
â”œâ”€â”€ copa_train_validated.jsonl                # finalValidatepassData
â”œâ”€â”€ generation_config.yaml
â””â”€â”€ README.md
```

---

## KeyOriginalthen

1. **First timeGeneratemustalreadyManual checkpoint**
   - Checkpoint1ï¼šReviewtop20 â†’ Generaterephrase few-shot
   - Checkpoint2ï¼šAnnotate21-80 â†’ Generatevalidation few-shot and test_set
   - Checkpoint3ï¼šTestprompt â†’ Tunedirect to â‰¥95%

2. **Parameter tuningExperimentRepeat use alreadyValidateprompt**
   - Inheritancetemplates/ in Configuration
   - OnlyModifyGenerateParameter
   - Directlyuserephrase_all.py
   - NoneneedRepeatmanual review

3. **allpromptAll needManualCreate**
   - initialpromptManualWrite
   - Few-shot examplesbymanual reviewAutomaticGenerate
   - PromptTunebyManualIterationComplete

4. **VersionManage**
   - drafts/: First timeGenerateConfiguration
   - templates/: ValidatepassTemplate
   - experiments/: Parameter tuningExperimentConfiguration
   - archive/: HistoryRecordï¼ˆcontainCompleteValidateHistoryï¼‰

---

## To be implementedToolclearSingle

### HighPriorityï¼ˆManual checkpointRequiredï¼‰
- [ ] `review_top20.py` - Checkpoint1manual reviewInterface
- [ ] `update_rest_prompt.py` - AutomaticInjectfew-shot to rephrase_rest.py
- [ ] `extract_samples.py` - Extractline21-80Sample
- [ ] `annotate_samples.py` - Checkpoint2Manual annotationInterface
- [ ] `generate_validation_test.py` - AutomaticGeneratevalidationTestScript
- [ ] `validate_prompt_test.py` - Testpromptaccuracyï¼ˆAutomaticGenerateï¼‰
- [ ] Modify`validate.py` - addGateCheck

###  in Priorityï¼ˆImproveExperienceï¼‰
- [ ] `tune_validation_prompt.py` - PromptTuneauxiliaryTool
- [ ] `compare_versions.py` - VersioncomparisonAnalysis
- [ ] Modify`generator.py` - supportAutomaticfew-shotInject

### LowPriorityï¼ˆelegant up Icing on cakeï¼‰
- [ ] WebInterfaceReplaceCLIReview/AnnotateTool
- [ ] AutomaticationpromptTuneRecommendation
- [ ] batchExperimentManageTool
